"""utils.py: Utilites"""

import kornia 
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from typing import Union,Tuple,Optional
import os
from easydict import EasyDict
import numpy as np

# Loading and Saving of NN
def save_checkpoint(epoch:int, metrics:dict ,net:nn.Module,opt:torch.optim.Optimizer,args:EasyDict, filename):
    """Save (whole) Pytorch checkpoint (for continued learning or inference)"""
    torch.save({
            'str_info': f"Epoch: {epoch} \nOptimizer name:  {str(opt)}\n Model architecture\n{str(net)}",
            'iter': epoch,
            'model_state_dict': net.state_dict(),
            'optimizer_state_dict': opt.state_dict(),
            'config_dict':args,
            'metrics' : metrics
            }, filename)


def load_checkpoint(device,net:Union[nn.Module,type],opt=None,filename=''):
    """Load Pytorch checkpoint (Net and optimizer architecture must be as in saved files)"""
    state = torch.load(filename)
    args = state['config_dict']

    if type(net) is type: # if architecture not specified, try saved args 
        net = net(args)
        device = args.device
    
    
    if net is not None:
        net.load_state_dict(state['model_state_dict'])

        if device is not None:
            net.to(device)
    
    if opt is not None:
        opt.load_state_dict(state['optimizer_state_dict'])
    
    epoch = state['iter']
    metrics = state['metrics']
    
    return epoch,metrics,net,opt,args


def get_device(gpu=3):   # Manually specify gpu
    if torch.cuda.is_available():
        device = torch.device(gpu)

    else:
        device='cpu'
    #print(f"Device loaded >> {device}")
    return device


def get_free_gpu():
    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')
    memory_available = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]
    index = np.argmax(memory_available[:-1])  # Skip the 7th card --- it is reserved for evaluation!!!
 
    return index   # Returns index of the gpu with the most memory available



def plot_batch(batch:torch.Tensor, num_rows=1,imgsize=(2,2)):
    """Plots batch [N,C,H,W] in separate N imgs,implicitly clips values (without warning)"""
    
    # Implicitly clip
    batch = batch.clip(0,1) if _is_torch_float(batch.dtype) else batch.clip(0,255)
    
    batch = kornia.utils.tensor_to_image(batch) 
    n = batch.shape[0]
    num_cols = n // num_rows + bool(n % num_rows)
    fig, ax = plt.subplots(num_rows, num_cols, figsize=(num_cols*imgsize[0], num_rows*imgsize[1]))
    
    ax = ax.reshape(1,-1) if ax.ndim == 1 else ax # enforce 2dim

    for i in range(n):
        row = i // num_cols
        col = i % num_cols
        ax[row, col].imshow(batch[i])
        ax[row, col].axis("off")
    plt.tight_layout()
    plt.show()

def _is_torch_float(dtype):
    return dtype == torch.float or dtype == torch.float16 or dtype == torch.float32 or dtype == torch.float64

def apply_transformation(transformation:nn.Module,features:torch.Tensor,targets:torch.Tensor):
    """Detect the type of task and apply transformation correspondingly"""
    
    if _is_task_segmentation(features,targets):
        return transformation(features,targets)
    else:
        return transformation(features),targets

def _is_task_segmentation(features:torch.Tensor,targets:torch.Tensor):
    return features.ndim == targets.ndim and features.shape[-2:] == targets.shape[-2:]

# 1a) One augumentation for each image in labeled batch
    # if utils._is_task_segmentation(labeled_batch,labels):
    #     # Segmentation -> Do transformation on both images and labels
    #     aug_labeled_batch,aug_labels = augumentation(labeled_batch,labels)
        
    # else:
    #     # Classification -> Do transformation only on images
    #     if isinstance(augumentation,custom_transforms.MyAugmentation):
    #         aug_labeled_batch,_ = augumentation(labeled_batch,None)
    #     else:
    #         aug_labeled_batch = augumentation(labeled_batch)

    #     aug_labels = labels 



def set_channel(batch, value, channel):
    """
    Generated by GPT-3 Model
    Set the value of a specified channel in a batch of images.

    Args:
        batch (torch.Tensor): Batch of images with shape (..., C, H, W).
        value (float): Value to set for the specified channel.
        channel (int): Index of the channel to set the value for (0 for red, 1 for green, 2 for blue).

    Returns:
        torch.Tensor: Batch of images with the specified channel set to the specified value.
    """

    if channel < 0 or channel >= batch.shape[-3]:
        raise ValueError("Channel must be between 0 and C-1.")

    # select the range of channels corresponding to the specified channel
    batch[..., channel:channel+1, :, :] = value

    return batch


# argparser types
import argparse
def _restricted_float(x):
    x = _float(x)
    if x < 0.0 or x > 1.0:
        raise argparse.ArgumentTypeError("%r not in range [0.0, 1.0]"%(x,))
    return x

def _float(x):
    is_valid_keyword,x = _try_keywords(x)
    if is_valid_keyword:
        return x 
    try:
        x = float(x)
    except ValueError:
        raise argparse.ArgumentTypeError("%r not a floating-point literal" % (x,))
    
    return x


def _str(x):
    is_valid_keyword,x = _try_keywords(x)
    if is_valid_keyword:
        return x  
    try:
        x = str(x)
    except ValueError:
        raise argparse.ArgumentTypeError("%r not a floating-point literal" % (x,))
    return x

def _try_keywords(x):

    is_valid_keyword = False
    if x.strip() == "None":
        x = None
        is_valid_keyword = True
    elif x.strip() == "True":
        x = True
        is_valid_keyword = True
    elif x.strip() == "False":
        x = False
        is_valid_keyword = True

    return is_valid_keyword, x


def lr_find(model: torch.nn.Module,
            train_dl: torch.utils.data.DataLoader,
            loss_fn: torch.nn.Module,
            args:EasyDict,
            transform: Optional[torch.nn.Module] = None,
            min_lr: float = 1e-7, max_lr: float = 100, steps: int = 50,
            optim_fn:torch.optim.Optimizer=torch.optim.SGD,
            verbose:bool=False) -> Tuple[torch.Tensor,torch.Tensor]:
    '''
    1. Save (on HDD or by deepcopy) the original CNN initialization.
    2. Create a sequence of learning rates from min_lr to max_lr in log space (use np.logspace)
    3. Start training the network, changing the learning rate after 1, 2 or 3 steps of the gradient descent and record the loss value corresponding to each learning rate in the sequence. **Important: steps == mini-batches, not epochs**. `lr_find` should be much faster, than overall training.
    4. (optional, for speed-up) Stop when the loss becomes larger than 10x the initial one.
    5. (optional) smooth the loss values.
    6. Restore model weights from save (1)
    :returns: Tuple (np.ndarray,np.ndarray)
    '''
    path = os.path.join(args.out,'lr_save.pt')
    
    torch.save(model.state_dict(),path)
    
    losses = torch.zeros(steps)
    lrs = torch.logspace(np.log10(min_lr),np.log10(max_lr),steps=steps)

    model.train()
    model.to(args.device)
    loss_fn.to(args.device)

    index = 0
    iter_dl = iter(train_dl)
    for lr_idx,lr in enumerate(lrs):

        # Set optimizer and start learning
        optimizer = optim_fn(model.parameters(),lr=lr,weight_decay=1e-4) 
        
        for i in range(3):
            # Write process of learning
            try:
                data,labels = next(iter_dl)
            except:
                iter_dl = iter(train_dl)
                data,labels = next(iter_dl)

            data = data.to(args.device)
            labels = labels.to(args.device)
            index +=1

            if transform is not None:
                data,targets = apply_transformation(transform,data,targets)

            optimizer.zero_grad()
            output = model.forward(data)
            
            loss = loss_fn(output,labels)
            if loss.ndim > 0:
                loss = torch.mean(loss)
            loss.backward()

            optimizer.step()
        
            
        if verbose:
             print(f'\rLearning rate [{lr_idx}] : {lr:.8f} \t Loss {loss:.6f}')

        losses[lr_idx] = loss.detach().cpu()

        if lr_idx > 0:
                if loss > 10*losses[lr_idx-1]:
                    if verbose:
                        print("Too bad learning loss, terminating!")

                    losses[lr_idx:] = loss.detach().cpu()
                    break
    
        
    # Load initial params
    model.load_state_dict(torch.load(path))    #if eval: map_location=torch.device('cpu')
    
    return losses, lrs
