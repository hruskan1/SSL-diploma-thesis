# Starting at 2023-05-17 12:30:14.320017
with args:
current_count : 0
epochs : 1024
kimg : 10000
K : 2
temperature : 0.5
alpha : 0.3
lambda_u : 50.0
rampup_length : 1024
n_labeled : 100
n_val : 0
batch_size : 4
learning_rate : 0.002
lr_scheduler : False
loss_ewa_coef : 0.98
device : cuda:0
dataset_path : /mnt/personal/hruskan1/CityScapes
mean_teacher_coef : 0.999
out : ./cityscape_cat@mix100_ll
resume : None
from_yml : None
log_period : 1
save_period : 0
debug : True
seed : 0
weight_decay : 4e-05
model_architecture : {'blocks': [{'type': 'encoder', 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'niters': 2, 'in_ch': 3, 'mid_ch': 64, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'encoder', 'niters': 2, 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'in_ch': 64, 'mid_ch': 128, 'out_ch': 128, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'encoder', 'niters': 2, 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'in_ch': 128, 'mid_ch': 256, 'out_ch': 256, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'bottleneck', 'niters': 3, 'in_ch': 256, 'mid_ch': 512, 'out_ch': 256, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 3, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 512, 'mid_ch': 256, 'out_ch': 128, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 3, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 256, 'mid_ch': 128, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 2, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 128, 'mid_ch': 64, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'classifier', 'in_ch': 64, 'out_ch': 8, 'conv_kernel': [1, 1], 'normalization_type': 'batch'}]}
img_size : [128, 256]
logpath : ./cityscape_cat@mix100_ll/log.txt
modelpath : ./cityscape_cat@mix100_ll/model
No resume point provided, will start from scratch!
Creating new network!
    Total params: 8.56M
epoch: 1 train loss: 0.4138 train acc: 87.6729 val loss: 0.0000 val acc: 0.0000 test loss: 0.4818 test acc: 84.5989 lam_u 0.0488 unlab loss: 0.4599 unlab acc: 85.8673LR: 0.002000
# Saving Model : ./cityscape_cat@mix100_ll/model-e1-a85-m.pt
epoch: 2 train loss: 0.1874 train acc: 94.4133 val loss: 0.0000 val acc: 0.0000 test loss: 0.3258 test acc: 89.6376 lam_u 0.0976 unlab loss: 0.3067 unlab acc: 90.5084LR: 0.002000
# Saving Model : ./cityscape_cat@mix100_ll/model-e2-a90-m.pt
epoch: 3 train loss: 0.1324 train acc: 96.0211 val loss: 0.0000 val acc: 0.0000 test loss: 0.3053 test acc: 90.3766 lam_u 0.1465 unlab loss: 0.2885 unlab acc: 91.1283LR: 0.002000
# Saving Model : ./cityscape_cat@mix100_ll/model-e3-a90-m.pt
epoch: 4 train loss: 0.1051 train acc: 96.7965 val loss: 0.0000 val acc: 0.0000 test loss: 0.2996 test acc: 90.6282 lam_u 0.1953 unlab loss: 0.2827 unlab acc: 91.3698LR: 0.002000
# Saving Model : ./cityscape_cat@mix100_ll/model-e4-a91-m.pt
epoch: 5 train loss: 0.0861 train acc: 97.3439 val loss: 0.0000 val acc: 0.0000 test loss: 0.2998 test acc: 90.7241 lam_u 0.2441 unlab loss: 0.2845 unlab acc: 91.4310LR: 0.002000
# Saving Model : ./cityscape_cat@mix100_ll/model-e5-a91-m.pt
epoch: 6 train loss: 0.0735 train acc: 97.7637 val loss: 0.0000 val acc: 0.0000 test loss: 0.3035 test acc: 90.7086 lam_u 0.2929 unlab loss: 0.2875 unlab acc: 91.4527LR: 0.002000
epoch: 7 train loss: 0.0624 train acc: 98.0926 val loss: 0.0000 val acc: 0.0000 test loss: 0.3065 test acc: 90.7285 lam_u 0.3418 unlab loss: 0.2895 unlab acc: 91.4841LR: 0.002000
# Saving Model : ./cityscape_cat@mix100_ll/model-e7-a91-m.pt
epoch: 8 train loss: 0.0554 train acc: 98.3214 val loss: 0.0000 val acc: 0.0000 test loss: 0.3092 test acc: 90.7550 lam_u 0.3906 unlab loss: 0.2917 unlab acc: 91.5115LR: 0.002000
# Saving Model : ./cityscape_cat@mix100_ll/model-e8-a91-m.pt
epoch: 9 train loss: 0.0500 train acc: 98.5038 val loss: 0.0000 val acc: 0.0000 test loss: 0.3127 test acc: 90.7065 lam_u 0.4394 unlab loss: 0.2952 unlab acc: 91.4634LR: 0.002000
epoch: 10 train loss: 0.0458 train acc: 98.6458 val loss: 0.0000 val acc: 0.0000 test loss: 0.3174 test acc: 90.6338 lam_u 0.4883 unlab loss: 0.2981 unlab acc: 91.4144LR: 0.002000
epoch: 11 train loss: 0.0420 train acc: 98.7770 val loss: 0.0000 val acc: 0.0000 test loss: 0.3192 test acc: 90.6616 lam_u 0.5371 unlab loss: 0.3020 unlab acc: 91.3907LR: 0.002000
epoch: 12 train loss: 0.0389 train acc: 98.8886 val loss: 0.0000 val acc: 0.0000 test loss: 0.3245 test acc: 90.5705 lam_u 0.5859 unlab loss: 0.3061 unlab acc: 91.3186LR: 0.002000
epoch: 13 train loss: 0.0368 train acc: 98.9599 val loss: 0.0000 val acc: 0.0000 test loss: 0.3273 test acc: 90.5535 lam_u 0.6347 unlab loss: 0.3110 unlab acc: 91.2335LR: 0.002000
epoch: 14 train loss: 0.0344 train acc: 99.0350 val loss: 0.0000 val acc: 0.0000 test loss: 0.3328 test acc: 90.4388 lam_u 0.6836 unlab loss: 0.3160 unlab acc: 91.1002LR: 0.002000
epoch: 15 train loss: 0.0330 train acc: 99.1029 val loss: 0.0000 val acc: 0.0000 test loss: 0.3392 test acc: 90.2489 lam_u 0.7324 unlab loss: 0.3215 unlab acc: 90.9675LR: 0.002000
epoch: 16 train loss: 0.0316 train acc: 99.1521 val loss: 0.0000 val acc: 0.0000 test loss: 0.3474 test acc: 90.0754 lam_u 0.7812 unlab loss: 0.3284 unlab acc: 90.7942LR: 0.002000
epoch: 17 train loss: 0.0308 train acc: 99.1815 val loss: 0.0000 val acc: 0.0000 test loss: 0.3525 test acc: 89.9212 lam_u 0.8301 unlab loss: 0.3359 unlab acc: 90.5863LR: 0.002000
epoch: 18 train loss: 0.0299 train acc: 99.2260 val loss: 0.0000 val acc: 0.0000 test loss: 0.3672 test acc: 89.5073 lam_u 0.8789 unlab loss: 0.3498 unlab acc: 90.2213LR: 0.002000
epoch: 19 train loss: 0.0290 train acc: 99.2442 val loss: 0.0000 val acc: 0.0000 test loss: 0.3776 test acc: 89.1500 lam_u 0.9277 unlab loss: 0.3620 unlab acc: 89.8280LR: 0.002000
epoch: 20 train loss: 0.0288 train acc: 99.2798 val loss: 0.0000 val acc: 0.0000 test loss: 0.3929 test acc: 88.7853 lam_u 0.9765 unlab loss: 0.3762 unlab acc: 89.3718LR: 0.002000
epoch: 21 train loss: 0.0291 train acc: 99.2919 val loss: 0.0000 val acc: 0.0000 test loss: 0.3988 test acc: 88.5156 lam_u 1.0254 unlab loss: 0.3821 unlab acc: 89.0894LR: 0.002000
epoch: 22 train loss: 0.0289 train acc: 99.3180 val loss: 0.0000 val acc: 0.0000 test loss: 0.4056 test acc: 88.3594 lam_u 1.0742 unlab loss: 0.3901 unlab acc: 88.8684LR: 0.002000
epoch: 23 train loss: 0.0287 train acc: 99.3240 val loss: 0.0000 val acc: 0.0000 test loss: 0.4110 test acc: 88.2194 lam_u 1.1230 unlab loss: 0.3981 unlab acc: 88.6481LR: 0.002000
epoch: 24 train loss: 0.0290 train acc: 99.3396 val loss: 0.0000 val acc: 0.0000 test loss: 0.4253 test acc: 87.7001 lam_u 1.1719 unlab loss: 0.4129 unlab acc: 88.0653LR: 0.002000
epoch: 25 train loss: 0.0293 train acc: 99.3460 val loss: 0.0000 val acc: 0.0000 test loss: 0.4223 test acc: 87.7295 lam_u 1.2207 unlab loss: 0.4080 unlab acc: 88.1639LR: 0.002000
epoch: 26 train loss: 0.0288 train acc: 99.3634 val loss: 0.0000 val acc: 0.0000 test loss: 0.4201 test acc: 87.7555 lam_u 1.2695 unlab loss: 0.4083 unlab acc: 88.1368LR: 0.002000
epoch: 27 train loss: 0.0290 train acc: 99.3740 val loss: 0.0000 val acc: 0.0000 test loss: 0.4261 test acc: 87.6607 lam_u 1.3183 unlab loss: 0.4159 unlab acc: 87.9717LR: 0.002000
epoch: 28 train loss: 0.0293 train acc: 99.3804 val loss: 0.0000 val acc: 0.0000 test loss: 0.4204 test acc: 88.0264 lam_u 1.3672 unlab loss: 0.4067 unlab acc: 88.4373LR: 0.002000
epoch: 29 train loss: 0.0297 train acc: 99.3832 val loss: 0.0000 val acc: 0.0000 test loss: 0.4197 test acc: 87.8830 lam_u 1.4160 unlab loss: 0.4096 unlab acc: 88.1602LR: 0.002000
epoch: 30 train loss: 0.0296 train acc: 99.3907 val loss: 0.0000 val acc: 0.0000 test loss: 0.4175 test acc: 87.9639 lam_u 1.4648 unlab loss: 0.4066 unlab acc: 88.2375LR: 0.002000
epoch: 31 train loss: 0.0290 train acc: 99.4186 val loss: 0.0000 val acc: 0.0000 test loss: 0.4286 test acc: 87.6595 lam_u 1.5137 unlab loss: 0.4178 unlab acc: 87.9869LR: 0.002000
epoch: 32 train loss: 0.0294 train acc: 99.4215 val loss: 0.0000 val acc: 0.0000 test loss: 0.4351 test acc: 87.5805 lam_u 1.5625 unlab loss: 0.4219 unlab acc: 87.9625LR: 0.002000
epoch: 33 train loss: 0.0305 train acc: 99.4183 val loss: 0.0000 val acc: 0.0000 test loss: 0.4361 test acc: 87.3957 lam_u 1.6113 unlab loss: 0.4211 unlab acc: 87.8409LR: 0.002000
epoch: 34 train loss: 0.0297 train acc: 99.4271 val loss: 0.0000 val acc: 0.0000 test loss: 0.4386 test acc: 87.5553 lam_u 1.6601 unlab loss: 0.4246 unlab acc: 87.9209LR: 0.002000
epoch: 35 train loss: 0.0295 train acc: 99.4387 val loss: 0.0000 val acc: 0.0000 test loss: 0.4207 test acc: 88.1724 lam_u 1.7090 unlab loss: 0.4089 unlab acc: 88.5128LR: 0.002000
epoch: 36 train loss: 0.0304 train acc: 99.4416 val loss: 0.0000 val acc: 0.0000 test loss: 0.4229 test acc: 87.9084 lam_u 1.7578 unlab loss: 0.4116 unlab acc: 88.2359LR: 0.002000
epoch: 37 train loss: 0.0294 train acc: 99.4507 val loss: 0.0000 val acc: 0.0000 test loss: 0.4200 test acc: 88.0898 lam_u 1.8066 unlab loss: 0.4092 unlab acc: 88.4450LR: 0.002000
epoch: 38 train loss: 0.0303 train acc: 99.4453 val loss: 0.0000 val acc: 0.0000 test loss: 0.4300 test acc: 87.8051 lam_u 1.8554 unlab loss: 0.4172 unlab acc: 88.1781LR: 0.002000
epoch: 39 train loss: 0.0301 train acc: 99.4632 val loss: 0.0000 val acc: 0.0000 test loss: 0.4439 test acc: 87.7642 lam_u 1.9043 unlab loss: 0.4301 unlab acc: 88.1263LR: 0.002000
epoch: 40 train loss: 0.0321 train acc: 99.4395 val loss: 0.0000 val acc: 0.0000 test loss: 0.4309 test acc: 87.9768 lam_u 1.9531 unlab loss: 0.4182 unlab acc: 88.2684LR: 0.002000
epoch: 41 train loss: 0.0314 train acc: 99.4533 val loss: 0.0000 val acc: 0.0000 test loss: 0.4363 test acc: 87.8098 lam_u 2.0019 unlab loss: 0.4261 unlab acc: 88.0348LR: 0.002000
epoch: 42 train loss: 0.0312 train acc: 99.4676 val loss: 0.0000 val acc: 0.0000 test loss: 0.4404 test acc: 87.6688 lam_u 2.0508 unlab loss: 0.4297 unlab acc: 87.9049LR: 0.002000
epoch: 43 train loss: 0.0316 train acc: 99.4705 val loss: 0.0000 val acc: 0.0000 test loss: 0.4440 test acc: 87.5835 lam_u 2.0996 unlab loss: 0.4360 unlab acc: 87.7498LR: 0.002000
epoch: 44 train loss: 0.0315 train acc: 99.4785 val loss: 0.0000 val acc: 0.0000 test loss: 0.4548 test acc: 87.0854 lam_u 2.1484 unlab loss: 0.4494 unlab acc: 87.2050LR: 0.002000
epoch: 45 train loss: 0.0314 train acc: 99.4870 val loss: 0.0000 val acc: 0.0000 test loss: 0.4536 test acc: 87.3111 lam_u 2.1972 unlab loss: 0.4421 unlab acc: 87.6084LR: 0.002000
epoch: 46 train loss: 0.0315 train acc: 99.4956 val loss: 0.0000 val acc: 0.0000 test loss: 0.4664 test acc: 87.0604 lam_u 2.2461 unlab loss: 0.4546 unlab acc: 87.3651LR: 0.002000
epoch: 47 train loss: 0.0322 train acc: 99.4910 val loss: 0.0000 val acc: 0.0000 test loss: 0.4549 test acc: 87.3484 lam_u 2.2949 unlab loss: 0.4475 unlab acc: 87.5125LR: 0.002000
epoch: 48 train loss: 0.0330 train acc: 99.4848 val loss: 0.0000 val acc: 0.0000 test loss: 0.4509 test acc: 87.3349 lam_u 2.3437 unlab loss: 0.4413 unlab acc: 87.5348LR: 0.002000
epoch: 49 train loss: 0.0318 train acc: 99.4964 val loss: 0.0000 val acc: 0.0000 test loss: 0.4483 test acc: 87.3478 lam_u 2.3926 unlab loss: 0.4424 unlab acc: 87.4698LR: 0.002000
epoch: 50 train loss: 0.0322 train acc: 99.4768 val loss: 0.0000 val acc: 0.0000 test loss: 0.4483 test acc: 87.3775 lam_u 2.4414 unlab loss: 0.4424 unlab acc: 87.4874LR: 0.002000
epoch: 51 train loss: 0.0325 train acc: 99.4900 val loss: 0.0000 val acc: 0.0000 test loss: 0.4689 test acc: 86.8170 lam_u 2.4902 unlab loss: 0.4598 unlab acc: 86.9905LR: 0.002000
epoch: 52 train loss: 0.0317 train acc: 99.4998 val loss: 0.0000 val acc: 0.0000 test loss: 0.4488 test acc: 87.4481 lam_u 2.5390 unlab loss: 0.4392 unlab acc: 87.6502LR: 0.002000
epoch: 53 train loss: 0.0327 train acc: 99.4925 val loss: 0.0000 val acc: 0.0000 test loss: 0.4566 test acc: 87.1996 lam_u 2.5879 unlab loss: 0.4473 unlab acc: 87.3988LR: 0.002000
epoch: 54 train loss: 0.0342 train acc: 99.4718 val loss: 0.0000 val acc: 0.0000 test loss: 0.4428 test acc: 87.4144 lam_u 2.6367 unlab loss: 0.4335 unlab acc: 87.6248LR: 0.002000
epoch: 55 train loss: 0.0334 train acc: 99.4959 val loss: 0.0000 val acc: 0.0000 test loss: 0.4557 test acc: 87.2374 lam_u 2.6855 unlab loss: 0.4449 unlab acc: 87.4900LR: 0.002000
epoch: 56 train loss: 0.0337 train acc: 99.4859 val loss: 0.0000 val acc: 0.0000 test loss: 0.4500 test acc: 87.4410 lam_u 2.7344 unlab loss: 0.4432 unlab acc: 87.5474LR: 0.002000
epoch: 57 train loss: 0.0371 train acc: 99.4297 val loss: 0.0000 val acc: 0.0000 test loss: 0.4494 test acc: 87.2282 lam_u 2.7832 unlab loss: 0.4396 unlab acc: 87.4985LR: 0.002000
epoch: 58 train loss: 0.0331 train acc: 99.4945 val loss: 0.0000 val acc: 0.0000 test loss: 0.4513 test acc: 87.1278 lam_u 2.8320 unlab loss: 0.4418 unlab acc: 87.2610LR: 0.002000
epoch: 59 train loss: 0.0341 train acc: 99.4823 val loss: 0.0000 val acc: 0.0000 test loss: 0.4713 test acc: 86.7193 lam_u 2.8808 unlab loss: 0.4576 unlab acc: 87.0242LR: 0.002000
epoch: 60 train loss: 0.0363 train acc: 99.4712 val loss: 0.0000 val acc: 0.0000 test loss: 0.4603 test acc: 86.9469 lam_u 2.9297 unlab loss: 0.4512 unlab acc: 87.0750LR: 0.002000
epoch: 61 train loss: 0.0340 train acc: 99.4895 val loss: 0.0000 val acc: 0.0000 test loss: 0.4667 test acc: 86.8885 lam_u 2.9785 unlab loss: 0.4531 unlab acc: 87.2235LR: 0.002000
epoch: 62 train loss: 0.0333 train acc: 99.4964 val loss: 0.0000 val acc: 0.0000 test loss: 0.4503 test acc: 87.3773 lam_u 3.0273 unlab loss: 0.4400 unlab acc: 87.6010LR: 0.002000
epoch: 63 train loss: 0.0341 train acc: 99.4978 val loss: 0.0000 val acc: 0.0000 test loss: 0.4781 test acc: 86.5148 lam_u 3.0762 unlab loss: 0.4709 unlab acc: 86.5934LR: 0.002000
epoch: 64 train loss: 0.0348 train acc: 99.5010 val loss: 0.0000 val acc: 0.0000 test loss: 0.4760 test acc: 86.5951 lam_u 3.1250 unlab loss: 0.4633 unlab acc: 86.8686LR: 0.002000
epoch: 65 train loss: 0.0372 train acc: 99.4678 val loss: 0.0000 val acc: 0.0000 test loss: 0.4693 test acc: 86.7448 lam_u 3.1738 unlab loss: 0.4585 unlab acc: 86.9644LR: 0.002000
epoch: 66 train loss: 0.0358 train acc: 99.4967 val loss: 0.0000 val acc: 0.0000 test loss: 0.4895 test acc: 86.2147 lam_u 3.2226 unlab loss: 0.4823 unlab acc: 86.3487LR: 0.002000
epoch: 67 train loss: 0.0352 train acc: 99.4982 val loss: 0.0000 val acc: 0.0000 test loss: 0.4780 test acc: 86.6420 lam_u 3.2715 unlab loss: 0.4715 unlab acc: 86.7341LR: 0.002000
epoch: 68 train loss: 0.0370 train acc: 99.4806 val loss: 0.0000 val acc: 0.0000 test loss: 0.4748 test acc: 86.6816 lam_u 3.3203 unlab loss: 0.4634 unlab acc: 86.9213LR: 0.002000
epoch: 69 train loss: 0.0350 train acc: 99.4860 val loss: 0.0000 val acc: 0.0000 test loss: 0.4739 test acc: 86.5170 lam_u 3.3691 unlab loss: 0.4691 unlab acc: 86.6142LR: 0.002000
epoch: 70 train loss: 0.0374 train acc: 99.4606 val loss: 0.0000 val acc: 0.0000 test loss: 0.4773 test acc: 86.2630 lam_u 3.4179 unlab loss: 0.4710 unlab acc: 86.3170LR: 0.002000
epoch: 71 train loss: 0.0363 train acc: 99.4946 val loss: 0.0000 val acc: 0.0000 test loss: 0.4908 test acc: 86.2347 lam_u 3.4668 unlab loss: 0.4806 unlab acc: 86.4782LR: 0.002000
epoch: 72 train loss: 0.0367 train acc: 99.4824 val loss: 0.0000 val acc: 0.0000 test loss: 0.4940 test acc: 86.1128 lam_u 3.5156 unlab loss: 0.4798 unlab acc: 86.4515LR: 0.002000
epoch: 73 train loss: 0.0359 train acc: 99.4852 val loss: 0.0000 val acc: 0.0000 test loss: 0.4849 test acc: 86.2435 lam_u 3.5644 unlab loss: 0.4807 unlab acc: 86.2461LR: 0.002000
epoch: 74 train loss: 0.0346 train acc: 99.5063 val loss: 0.0000 val acc: 0.0000 test loss: 0.4820 test acc: 86.3454 lam_u 3.6133 unlab loss: 0.4810 unlab acc: 86.1682LR: 0.002000
epoch: 75 train loss: 0.0372 train acc: 99.4585 val loss: 0.0000 val acc: 0.0000 test loss: 0.4655 test acc: 86.7628 lam_u 3.6621 unlab loss: 0.4627 unlab acc: 86.7396LR: 0.002000
epoch: 76 train loss: 0.0369 train acc: 99.4545 val loss: 0.0000 val acc: 0.0000 test loss: 0.4821 test acc: 86.4192 lam_u 3.7109 unlab loss: 0.4766 unlab acc: 86.4220LR: 0.002000
epoch: 77 train loss: 0.0365 train acc: 99.4832 val loss: 0.0000 val acc: 0.0000 test loss: 0.4702 test acc: 86.8484 lam_u 3.7597 unlab loss: 0.4705 unlab acc: 86.7340LR: 0.002000
epoch: 78 train loss: 0.0383 train acc: 99.4915 val loss: 0.0000 val acc: 0.0000 test loss: 0.4922 test acc: 86.1962 lam_u 3.8086 unlab loss: 0.4904 unlab acc: 86.0529LR: 0.002000
epoch: 79 train loss: 0.0353 train acc: 99.4859 val loss: 0.0000 val acc: 0.0000 test loss: 0.4742 test acc: 86.7174 lam_u 3.8574 unlab loss: 0.4735 unlab acc: 86.5915LR: 0.002000
epoch: 80 train loss: 0.0405 train acc: 99.4390 val loss: 0.0000 val acc: 0.0000 test loss: 0.4739 test acc: 86.6125 lam_u 3.9062 unlab loss: 0.4697 unlab acc: 86.5964LR: 0.002000
epoch: 81 train loss: 0.0361 train acc: 99.4949 val loss: 0.0000 val acc: 0.0000 test loss: 0.4800 test acc: 86.5812 lam_u 3.9551 unlab loss: 0.4780 unlab acc: 86.4562LR: 0.002000
epoch: 82 train loss: 0.0432 train acc: 99.4322 val loss: 0.0000 val acc: 0.0000 test loss: 0.4611 test acc: 86.9533 lam_u 4.0039 unlab loss: 0.4549 unlab acc: 86.9686LR: 0.002000
epoch: 83 train loss: 0.0368 train acc: 99.4581 val loss: 0.0000 val acc: 0.0000 test loss: 0.4718 test acc: 86.9064 lam_u 4.0527 unlab loss: 0.4642 unlab acc: 86.9897LR: 0.002000
epoch: 84 train loss: 0.0361 train acc: 99.4739 val loss: 0.0000 val acc: 0.0000 test loss: 0.4978 test acc: 86.1661 lam_u 4.1015 unlab loss: 0.4944 unlab acc: 85.9411LR: 0.002000
epoch: 85 train loss: 0.0357 train acc: 99.4668 val loss: 0.0000 val acc: 0.0000 test loss: 0.4659 test acc: 86.8985 lam_u 4.1504 unlab loss: 0.4631 unlab acc: 86.7872LR: 0.002000
epoch: 86 train loss: 0.0395 train acc: 99.4507 val loss: 0.0000 val acc: 0.0000 test loss: 0.4658 test acc: 87.0744 lam_u 4.1992 unlab loss: 0.4590 unlab acc: 87.1976LR: 0.002000
epoch: 87 train loss: 0.0377 train acc: 99.4797 val loss: 0.0000 val acc: 0.0000 test loss: 0.4852 test acc: 86.5227 lam_u 4.2480 unlab loss: 0.4866 unlab acc: 86.2604LR: 0.002000
epoch: 88 train loss: 0.0389 train acc: 99.4686 val loss: 0.0000 val acc: 0.0000 test loss: 0.4943 test acc: 86.0573 lam_u 4.2969 unlab loss: 0.4960 unlab acc: 85.7031LR: 0.002000
epoch: 89 train loss: 0.0374 train acc: 99.4669 val loss: 0.0000 val acc: 0.0000 test loss: 0.4620 test acc: 87.1421 lam_u 4.3457 unlab loss: 0.4563 unlab acc: 87.2183LR: 0.002000
epoch: 90 train loss: 0.0413 train acc: 99.4466 val loss: 0.0000 val acc: 0.0000 test loss: 0.4614 test acc: 87.2018 lam_u 4.3945 unlab loss: 0.4589 unlab acc: 87.1361LR: 0.002000
epoch: 91 train loss: 0.0382 train acc: 99.4717 val loss: 0.0000 val acc: 0.0000 test loss: 0.4792 test acc: 86.6047 lam_u 4.4433 unlab loss: 0.4776 unlab acc: 86.4429LR: 0.002000
epoch: 92 train loss: 0.0391 train acc: 99.4521 val loss: 0.0000 val acc: 0.0000 test loss: 0.4624 test acc: 87.0142 lam_u 4.4922 unlab loss: 0.4551 unlab acc: 87.0385LR: 0.002000
epoch: 93 train loss: 0.0393 train acc: 99.4760 val loss: 0.0000 val acc: 0.0000 test loss: 0.4833 test acc: 86.5935 lam_u 4.5410 unlab loss: 0.4776 unlab acc: 86.5487LR: 0.002000
epoch: 94 train loss: 0.0482 train acc: 99.4112 val loss: 0.0000 val acc: 0.0000 test loss: 0.4659 test acc: 86.8958 lam_u 4.5898 unlab loss: 0.4597 unlab acc: 86.9422LR: 0.002000
epoch: 95 train loss: 0.0416 train acc: 99.4452 val loss: 0.0000 val acc: 0.0000 test loss: 0.4591 test acc: 87.2647 lam_u 4.6387 unlab loss: 0.4537 unlab acc: 87.2838LR: 0.002000
epoch: 96 train loss: 0.0389 train acc: 99.4535 val loss: 0.0000 val acc: 0.0000 test loss: 0.4729 test acc: 86.9924 lam_u 4.6875 unlab loss: 0.4680 unlab acc: 86.9904LR: 0.002000
epoch: 97 train loss: 0.0378 train acc: 99.4758 val loss: 0.0000 val acc: 0.0000 test loss: 0.4852 test acc: 86.7486 lam_u 4.7363 unlab loss: 0.4816 unlab acc: 86.6912LR: 0.002000
epoch: 98 train loss: 0.0474 train acc: 99.3876 val loss: 0.0000 val acc: 0.0000 test loss: 0.4618 test acc: 87.1193 lam_u 4.7851 unlab loss: 0.4597 unlab acc: 87.0482LR: 0.002000
epoch: 99 train loss: 0.0384 train acc: 99.4648 val loss: 0.0000 val acc: 0.0000 test loss: 0.5085 test acc: 86.0415 lam_u 4.8340 unlab loss: 0.5030 unlab acc: 86.0810LR: 0.002000
epoch: 100 train loss: 0.0417 train acc: 99.4470 val loss: 0.0000 val acc: 0.0000 test loss: 0.4965 test acc: 86.1493 lam_u 4.8828 unlab loss: 0.4955 unlab acc: 86.0301LR: 0.002000
epoch: 101 train loss: 0.0414 train acc: 99.4493 val loss: 0.0000 val acc: 0.0000 test loss: 0.5154 test acc: 85.6803 lam_u 4.9316 unlab loss: 0.5116 unlab acc: 85.7224LR: 0.002000
epoch: 102 train loss: 0.0410 train acc: 99.4480 val loss: 0.0000 val acc: 0.0000 test loss: 0.4799 test acc: 86.4851 lam_u 4.9804 unlab loss: 0.4813 unlab acc: 86.2358LR: 0.002000
epoch: 103 train loss: 0.0412 train acc: 99.4303 val loss: 0.0000 val acc: 0.0000 test loss: 0.4851 test acc: 86.2930 lam_u 5.0293 unlab loss: 0.4841 unlab acc: 86.2385LR: 0.002000
epoch: 104 train loss: 0.0400 train acc: 99.4318 val loss: 0.0000 val acc: 0.0000 test loss: 0.4959 test acc: 86.0301 lam_u 5.0781 unlab loss: 0.5014 unlab acc: 85.7921LR: 0.002000
epoch: 105 train loss: 0.0433 train acc: 99.3992 val loss: 0.0000 val acc: 0.0000 test loss: 0.4753 test acc: 86.6106 lam_u 5.1269 unlab loss: 0.4727 unlab acc: 86.6419LR: 0.002000
epoch: 106 train loss: 0.0407 train acc: 99.4218 val loss: 0.0000 val acc: 0.0000 test loss: 0.4713 test acc: 86.9708 lam_u 5.1758 unlab loss: 0.4680 unlab acc: 87.0189LR: 0.002000
epoch: 107 train loss: 0.0412 train acc: 99.4165 val loss: 0.0000 val acc: 0.0000 test loss: 0.4880 test acc: 86.4736 lam_u 5.2246 unlab loss: 0.4835 unlab acc: 86.4304LR: 0.002000
epoch: 108 train loss: 0.0427 train acc: 99.4223 val loss: 0.0000 val acc: 0.0000 test loss: 0.5007 test acc: 86.0003 lam_u 5.2734 unlab loss: 0.4995 unlab acc: 85.9323LR: 0.002000
epoch: 109 train loss: 0.0391 train acc: 99.4282 val loss: 0.0000 val acc: 0.0000 test loss: 0.4831 test acc: 86.7198 lam_u 5.3222 unlab loss: 0.4852 unlab acc: 86.5013LR: 0.002000
epoch: 110 train loss: 0.0382 train acc: 99.4630 val loss: 0.0000 val acc: 0.0000 test loss: 0.5150 test acc: 85.5048 lam_u 5.3711 unlab loss: 0.5189 unlab acc: 85.1515LR: 0.002000
epoch: 111 train loss: 0.0398 train acc: 99.4358 val loss: 0.0000 val acc: 0.0000 test loss: 0.4826 test acc: 86.6307 lam_u 5.4199 unlab loss: 0.4849 unlab acc: 86.3921LR: 0.002000
epoch: 112 train loss: 0.0418 train acc: 99.4189 val loss: 0.0000 val acc: 0.0000 test loss: 0.4997 test acc: 86.3878 lam_u 5.4687 unlab loss: 0.4990 unlab acc: 86.3856LR: 0.002000
epoch: 113 train loss: 0.0419 train acc: 99.4257 val loss: 0.0000 val acc: 0.0000 test loss: 0.4789 test acc: 86.5606 lam_u 5.5176 unlab loss: 0.4740 unlab acc: 86.6646LR: 0.002000
