# Starting at 2023-05-17 12:29:37.693355
with args:
current_count : 0
epochs : 1024
kimg : 10000
K : 2
temperature : 0.5
alpha : 0.3
lambda_u : 50.0
rampup_length : 1024
n_labeled : 10
n_val : 0
batch_size : 4
learning_rate : 0.002
lr_scheduler : False
loss_ewa_coef : 0.98
device : cuda:0
dataset_path : /mnt/personal/hruskan1/CityScapes
mean_teacher_coef : 0.999
out : ./cityscape_cat@mix10_ll
resume : None
from_yml : None
log_period : 1
save_period : 0
debug : True
seed : 0
weight_decay : 4e-05
model_architecture : {'blocks': [{'type': 'encoder', 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'niters': 2, 'in_ch': 3, 'mid_ch': 64, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'encoder', 'niters': 2, 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'in_ch': 64, 'mid_ch': 128, 'out_ch': 128, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'encoder', 'niters': 2, 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'in_ch': 128, 'mid_ch': 256, 'out_ch': 256, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'bottleneck', 'niters': 3, 'in_ch': 256, 'mid_ch': 512, 'out_ch': 256, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 3, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 512, 'mid_ch': 256, 'out_ch': 128, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 3, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 256, 'mid_ch': 128, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 2, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 128, 'mid_ch': 64, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'classifier', 'in_ch': 64, 'out_ch': 8, 'conv_kernel': [1, 1], 'normalization_type': 'batch'}]}
img_size : [128, 256]
logpath : ./cityscape_cat@mix10_ll/log.txt
modelpath : ./cityscape_cat@mix10_ll/model
No resume point provided, will start from scratch!
Creating new network!
    Total params: 8.56M
epoch: 1 train loss: 0.3805 train acc: 86.5676 val loss: 0.0000 val acc: 0.0000 test loss: 0.6833 test acc: 75.4166 lam_u 0.0488 unlab loss: 0.6694 unlab acc: 75.5953LR: 0.002000
# Saving Model : ./cityscape_cat@mix10_ll/model-e1-a75-m.pt
epoch: 2 train loss: 0.0770 train acc: 98.0995 val loss: 0.0000 val acc: 0.0000 test loss: 0.5205 test acc: 82.9981 lam_u 0.0976 unlab loss: 0.4911 unlab acc: 84.1580LR: 0.002000
# Saving Model : ./cityscape_cat@mix10_ll/model-e2-a83-m.pt
epoch: 3 train loss: 0.0315 train acc: 99.4175 val loss: 0.0000 val acc: 0.0000 test loss: 0.5323 test acc: 82.9823 lam_u 0.1465 unlab loss: 0.4957 unlab acc: 84.2550LR: 0.002000
epoch: 4 train loss: 0.0204 train acc: 99.7641 val loss: 0.0000 val acc: 0.0000 test loss: 0.5412 test acc: 82.9369 lam_u 0.1953 unlab loss: 0.5004 unlab acc: 84.1904LR: 0.002000
epoch: 5 train loss: 0.0142 train acc: 99.9263 val loss: 0.0000 val acc: 0.0000 test loss: 0.5375 test acc: 83.2537 lam_u 0.2441 unlab loss: 0.4973 unlab acc: 84.4077LR: 0.002000
# Saving Model : ./cityscape_cat@mix10_ll/model-e5-a83-m.pt
epoch: 6 train loss: 0.0122 train acc: 99.9723 val loss: 0.0000 val acc: 0.0000 test loss: 0.5256 test acc: 83.6828 lam_u 0.2929 unlab loss: 0.4918 unlab acc: 84.5791LR: 0.002000
# Saving Model : ./cityscape_cat@mix10_ll/model-e6-a84-m.pt
epoch: 7 train loss: 0.0111 train acc: 99.9901 val loss: 0.0000 val acc: 0.0000 test loss: 0.5228 test acc: 83.9594 lam_u 0.3418 unlab loss: 0.4879 unlab acc: 84.8769LR: 0.002000
# Saving Model : ./cityscape_cat@mix10_ll/model-e7-a84-m.pt
epoch: 8 train loss: 0.0100 train acc: 99.9958 val loss: 0.0000 val acc: 0.0000 test loss: 0.5148 test acc: 84.5304 lam_u 0.3906 unlab loss: 0.4817 unlab acc: 85.4261LR: 0.002000
# Saving Model : ./cityscape_cat@mix10_ll/model-e8-a85-m.pt
epoch: 9 train loss: 0.0105 train acc: 99.9978 val loss: 0.0000 val acc: 0.0000 test loss: 0.5269 test acc: 84.3644 lam_u 0.4394 unlab loss: 0.4962 unlab acc: 85.1587LR: 0.002000
epoch: 10 train loss: 0.0100 train acc: 99.9983 val loss: 0.0000 val acc: 0.0000 test loss: 0.5413 test acc: 84.0352 lam_u 0.4883 unlab loss: 0.5076 unlab acc: 84.9078LR: 0.002000
epoch: 11 train loss: 0.0103 train acc: 99.9983 val loss: 0.0000 val acc: 0.0000 test loss: 0.5670 test acc: 83.2601 lam_u 0.5371 unlab loss: 0.5361 unlab acc: 84.0749LR: 0.002000
epoch: 12 train loss: 0.0111 train acc: 99.9978 val loss: 0.0000 val acc: 0.0000 test loss: 0.5916 test acc: 82.6625 lam_u 0.5859 unlab loss: 0.5618 unlab acc: 83.4106LR: 0.002000
epoch: 13 train loss: 0.0121 train acc: 99.9991 val loss: 0.0000 val acc: 0.0000 test loss: 0.6260 test acc: 81.5498 lam_u 0.6347 unlab loss: 0.5931 unlab acc: 82.3382LR: 0.002000
epoch: 14 train loss: 0.0127 train acc: 99.9996 val loss: 0.0000 val acc: 0.0000 test loss: 0.6455 test acc: 81.1769 lam_u 0.6836 unlab loss: 0.6105 unlab acc: 82.0447LR: 0.002000
epoch: 15 train loss: 0.0124 train acc: 99.9996 val loss: 0.0000 val acc: 0.0000 test loss: 0.6745 test acc: 81.2127 lam_u 0.7324 unlab loss: 0.6343 unlab acc: 82.0520LR: 0.002000
epoch: 16 train loss: 0.0136 train acc: 99.9991 val loss: 0.0000 val acc: 0.0000 test loss: 0.6838 test acc: 80.9601 lam_u 0.7812 unlab loss: 0.6447 unlab acc: 81.7316LR: 0.002000
epoch: 17 train loss: 0.0137 train acc: 99.9996 val loss: 0.0000 val acc: 0.0000 test loss: 0.7070 test acc: 80.4576 lam_u 0.8301 unlab loss: 0.6742 unlab acc: 81.1223LR: 0.002000
epoch: 18 train loss: 0.0145 train acc: 100.0000 val loss: 0.0000 val acc: 0.0000 test loss: 0.7113 test acc: 80.8520 lam_u 0.8789 unlab loss: 0.6823 unlab acc: 81.2974LR: 0.002000
epoch: 19 train loss: 0.0141 train acc: 99.9987 val loss: 0.0000 val acc: 0.0000 test loss: 0.7220 test acc: 80.4088 lam_u 0.9277 unlab loss: 0.6924 unlab acc: 81.0220LR: 0.002000
epoch: 20 train loss: 0.0145 train acc: 99.9996 val loss: 0.0000 val acc: 0.0000 test loss: 0.7251 test acc: 80.5028 lam_u 0.9765 unlab loss: 0.6934 unlab acc: 81.0083LR: 0.002000
epoch: 21 train loss: 0.0145 train acc: 99.9991 val loss: 0.0000 val acc: 0.0000 test loss: 0.7179 test acc: 80.8007 lam_u 1.0254 unlab loss: 0.6848 unlab acc: 81.3325LR: 0.002000
epoch: 22 train loss: 0.0150 train acc: 99.9996 val loss: 0.0000 val acc: 0.0000 test loss: 0.7348 test acc: 80.5353 lam_u 1.0742 unlab loss: 0.7091 unlab acc: 81.0508LR: 0.002000
epoch: 23 train loss: 0.0155 train acc: 99.9996 val loss: 0.0000 val acc: 0.0000 test loss: 0.7847 test acc: 79.1049 lam_u 1.1230 unlab loss: 0.7504 unlab acc: 79.7239LR: 0.002000
epoch: 24 train loss: 0.0153 train acc: 99.9996 val loss: 0.0000 val acc: 0.0000 test loss: 0.7562 test acc: 79.8802 lam_u 1.1719 unlab loss: 0.7250 unlab acc: 80.4377LR: 0.002000
epoch: 25 train loss: 0.0169 train acc: 99.9991 val loss: 0.0000 val acc: 0.0000 test loss: 0.7406 test acc: 80.1715 lam_u 1.2207 unlab loss: 0.7049 unlab acc: 80.8124LR: 0.002000
epoch: 26 train loss: 0.0166 train acc: 99.9991 val loss: 0.0000 val acc: 0.0000 test loss: 0.7589 test acc: 79.8007 lam_u 1.2695 unlab loss: 0.7307 unlab acc: 80.4172LR: 0.002000
epoch: 27 train loss: 0.0159 train acc: 100.0000 val loss: 0.0000 val acc: 0.0000 test loss: 0.7366 test acc: 79.9309 lam_u 1.3183 unlab loss: 0.7053 unlab acc: 80.5976LR: 0.002000
epoch: 28 train loss: 0.0173 train acc: 100.0000 val loss: 0.0000 val acc: 0.0000 test loss: 0.7732 test acc: 79.6049 lam_u 1.3672 unlab loss: 0.7485 unlab acc: 80.1321LR: 0.002000
epoch: 29 train loss: 0.0185 train acc: 99.9996 val loss: 0.0000 val acc: 0.0000 test loss: 0.7797 test acc: 79.2069 lam_u 1.4160 unlab loss: 0.7422 unlab acc: 80.0532LR: 0.002000
epoch: 30 train loss: 0.0172 train acc: 99.9991 val loss: 0.0000 val acc: 0.0000 test loss: 0.7112 test acc: 80.2971 lam_u 1.4648 unlab loss: 0.6816 unlab acc: 80.8192LR: 0.002000
epoch: 31 train loss: 0.0182 train acc: 99.9996 val loss: 0.0000 val acc: 0.0000 test loss: 0.7411 test acc: 79.8985 lam_u 1.5137 unlab loss: 0.7123 unlab acc: 80.3985LR: 0.002000
epoch: 32 train loss: 0.0189 train acc: 99.9991 val loss: 0.0000 val acc: 0.0000 test loss: 0.7725 test acc: 79.2219 lam_u 1.5625 unlab loss: 0.7318 unlab acc: 79.8660LR: 0.002000
epoch: 33 train loss: 0.0187 train acc: 99.9991 val loss: 0.0000 val acc: 0.0000 test loss: 0.7908 test acc: 78.9775 lam_u 1.6113 unlab loss: 0.7517 unlab acc: 79.5091LR: 0.002000
epoch: 34 train loss: 0.0187 train acc: 100.0000 val loss: 0.0000 val acc: 0.0000 test loss: 0.8235 test acc: 77.7054 lam_u 1.6601 unlab loss: 0.7802 unlab acc: 78.4035LR: 0.002000
epoch: 35 train loss: 0.0193 train acc: 99.9996 val loss: 0.0000 val acc: 0.0000 test loss: 0.7723 test acc: 79.3801 lam_u 1.7090 unlab loss: 0.7354 unlab acc: 79.8366LR: 0.002000
