# Starting at 2023-05-17 12:30:44.677890
with args:
current_count : 0
epochs : 1024
kimg : 10000
K : 2
temperature : 0.5
alpha : 0.3
lambda_u : 50.0
rampup_length : 1024
n_labeled : 500
n_val : 0
batch_size : 4
learning_rate : 0.002
lr_scheduler : False
loss_ewa_coef : 0.98
device : cuda:0
dataset_path : /mnt/personal/hruskan1/CityScapes
mean_teacher_coef : 0.999
out : ./cityscape_cat@mix500_ll
resume : None
from_yml : None
log_period : 1
save_period : 0
debug : True
seed : 0
weight_decay : 4e-05
model_architecture : {'blocks': [{'type': 'encoder', 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'niters': 2, 'in_ch': 3, 'mid_ch': 64, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'encoder', 'niters': 2, 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'in_ch': 64, 'mid_ch': 128, 'out_ch': 128, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'encoder', 'niters': 2, 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'in_ch': 128, 'mid_ch': 256, 'out_ch': 256, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'bottleneck', 'niters': 3, 'in_ch': 256, 'mid_ch': 512, 'out_ch': 256, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 3, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 512, 'mid_ch': 256, 'out_ch': 128, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 3, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 256, 'mid_ch': 128, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 2, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 128, 'mid_ch': 64, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'classifier', 'in_ch': 64, 'out_ch': 8, 'conv_kernel': [1, 1], 'normalization_type': 'batch'}]}
img_size : [128, 256]
logpath : ./cityscape_cat@mix500_ll/log.txt
modelpath : ./cityscape_cat@mix500_ll/model
No resume point provided, will start from scratch!
Creating new network!
    Total params: 8.56M
epoch: 1 train loss: 0.4864 train acc: 84.4755 val loss: 0.0000 val acc: 0.0000 test loss: 0.5028 test acc: 83.6573 lam_u 0.0488 unlab loss: 0.4825 unlab acc: 84.7888LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e1-a84-m.pt
epoch: 2 train loss: 0.2730 train acc: 91.4977 val loss: 0.0000 val acc: 0.0000 test loss: 0.3083 test acc: 90.2667 lam_u 0.0976 unlab loss: 0.2895 unlab acc: 90.9210LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e2-a90-m.pt
epoch: 3 train loss: 0.2153 train acc: 93.1613 val loss: 0.0000 val acc: 0.0000 test loss: 0.2651 test acc: 91.4364 lam_u 0.1465 unlab loss: 0.2450 unlab acc: 92.1398LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e3-a91-m.pt
epoch: 4 train loss: 0.1844 train acc: 94.1111 val loss: 0.0000 val acc: 0.0000 test loss: 0.2441 test acc: 92.0432 lam_u 0.1953 unlab loss: 0.2240 unlab acc: 92.7847LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e4-a92-m.pt
epoch: 5 train loss: 0.1615 train acc: 94.9013 val loss: 0.0000 val acc: 0.0000 test loss: 0.2294 test acc: 92.5333 lam_u 0.2441 unlab loss: 0.2098 unlab acc: 93.2732LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e5-a93-m.pt
epoch: 6 train loss: 0.1446 train acc: 95.4409 val loss: 0.0000 val acc: 0.0000 test loss: 0.2185 test acc: 92.8637 lam_u 0.2929 unlab loss: 0.2017 unlab acc: 93.5311LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e6-a93-m.pt
epoch: 7 train loss: 0.1295 train acc: 95.8625 val loss: 0.0000 val acc: 0.0000 test loss: 0.2127 test acc: 93.0462 lam_u 0.3418 unlab loss: 0.1967 unlab acc: 93.6737LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e7-a93-m.pt
epoch: 8 train loss: 0.1186 train acc: 96.1857 val loss: 0.0000 val acc: 0.0000 test loss: 0.2088 test acc: 93.1461 lam_u 0.3906 unlab loss: 0.1930 unlab acc: 93.7921LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e8-a93-m.pt
epoch: 9 train loss: 0.1104 train acc: 96.4111 val loss: 0.0000 val acc: 0.0000 test loss: 0.2089 test acc: 93.1455 lam_u 0.4394 unlab loss: 0.1920 unlab acc: 93.8413LR: 0.002000
epoch: 10 train loss: 0.1041 train acc: 96.5973 val loss: 0.0000 val acc: 0.0000 test loss: 0.2078 test acc: 93.2286 lam_u 0.4883 unlab loss: 0.1921 unlab acc: 93.8667LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e10-a93-m.pt
epoch: 11 train loss: 0.0979 train acc: 96.7571 val loss: 0.0000 val acc: 0.0000 test loss: 0.2070 test acc: 93.2725 lam_u 0.5371 unlab loss: 0.1918 unlab acc: 93.9184LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e11-a93-m.pt
epoch: 12 train loss: 0.0934 train acc: 96.8864 val loss: 0.0000 val acc: 0.0000 test loss: 0.2067 test acc: 93.3076 lam_u 0.5859 unlab loss: 0.1909 unlab acc: 93.9647LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e12-a93-m.pt
epoch: 13 train loss: 0.0897 train acc: 97.0031 val loss: 0.0000 val acc: 0.0000 test loss: 0.2069 test acc: 93.3459 lam_u 0.6347 unlab loss: 0.1915 unlab acc: 93.9897LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e13-a93-m.pt
epoch: 14 train loss: 0.0889 train acc: 97.0787 val loss: 0.0000 val acc: 0.0000 test loss: 0.2090 test acc: 93.2731 lam_u 0.6836 unlab loss: 0.1939 unlab acc: 93.9370LR: 0.002000
epoch: 15 train loss: 0.0845 train acc: 97.1640 val loss: 0.0000 val acc: 0.0000 test loss: 0.2086 test acc: 93.3513 lam_u 0.7324 unlab loss: 0.1924 unlab acc: 93.9990LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e15-a93-m.pt
epoch: 16 train loss: 0.0813 train acc: 97.2691 val loss: 0.0000 val acc: 0.0000 test loss: 0.2085 test acc: 93.3531 lam_u 0.7812 unlab loss: 0.1935 unlab acc: 94.0104LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e16-a93-m.pt
epoch: 17 train loss: 0.0785 train acc: 97.3507 val loss: 0.0000 val acc: 0.0000 test loss: 0.2088 test acc: 93.3657 lam_u 0.8301 unlab loss: 0.1950 unlab acc: 93.9880LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e17-a93-m.pt
epoch: 18 train loss: 0.0764 train acc: 97.4127 val loss: 0.0000 val acc: 0.0000 test loss: 0.2096 test acc: 93.3964 lam_u 0.8789 unlab loss: 0.1955 unlab acc: 93.9890LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e18-a93-m.pt
epoch: 19 train loss: 0.0756 train acc: 97.4518 val loss: 0.0000 val acc: 0.0000 test loss: 0.2081 test acc: 93.4176 lam_u 0.9277 unlab loss: 0.1950 unlab acc: 93.9997LR: 0.002000
# Saving Model : ./cityscape_cat@mix500_ll/model-e19-a93-m.pt
epoch: 20 train loss: 0.0727 train acc: 97.5403 val loss: 0.0000 val acc: 0.0000 test loss: 0.2101 test acc: 93.3920 lam_u 0.9765 unlab loss: 0.1955 unlab acc: 93.9963LR: 0.002000
epoch: 21 train loss: 0.0714 train acc: 97.5962 val loss: 0.0000 val acc: 0.0000 test loss: 0.2122 test acc: 93.3427 lam_u 1.0254 unlab loss: 0.1975 unlab acc: 93.9814LR: 0.002000
epoch: 22 train loss: 0.0698 train acc: 97.6559 val loss: 0.0000 val acc: 0.0000 test loss: 0.2123 test acc: 93.3714 lam_u 1.0742 unlab loss: 0.1986 unlab acc: 93.9712LR: 0.002000
epoch: 23 train loss: 0.0687 train acc: 97.6690 val loss: 0.0000 val acc: 0.0000 test loss: 0.2124 test acc: 93.3344 lam_u 1.1230 unlab loss: 0.1985 unlab acc: 93.9699LR: 0.002000
epoch: 24 train loss: 0.0701 train acc: 97.6688 val loss: 0.0000 val acc: 0.0000 test loss: 0.2122 test acc: 93.3246 lam_u 1.1719 unlab loss: 0.1984 unlab acc: 93.9521LR: 0.002000
epoch: 25 train loss: 0.0671 train acc: 97.7518 val loss: 0.0000 val acc: 0.0000 test loss: 0.2136 test acc: 93.3506 lam_u 1.2207 unlab loss: 0.2012 unlab acc: 93.9335LR: 0.002000
epoch: 26 train loss: 0.0659 train acc: 97.7820 val loss: 0.0000 val acc: 0.0000 test loss: 0.2147 test acc: 93.3691 lam_u 1.2695 unlab loss: 0.2020 unlab acc: 93.9408LR: 0.002000
epoch: 27 train loss: 0.0669 train acc: 97.7925 val loss: 0.0000 val acc: 0.0000 test loss: 0.2152 test acc: 93.2967 lam_u 1.3183 unlab loss: 0.2006 unlab acc: 93.9173LR: 0.002000
epoch: 28 train loss: 0.0662 train acc: 97.8031 val loss: 0.0000 val acc: 0.0000 test loss: 0.2194 test acc: 93.2556 lam_u 1.3672 unlab loss: 0.2057 unlab acc: 93.8424LR: 0.002000
epoch: 29 train loss: 0.0633 train acc: 97.8851 val loss: 0.0000 val acc: 0.0000 test loss: 0.2193 test acc: 93.2640 lam_u 1.4160 unlab loss: 0.2072 unlab acc: 93.8290LR: 0.002000
epoch: 30 train loss: 0.0623 train acc: 97.9060 val loss: 0.0000 val acc: 0.0000 test loss: 0.2200 test acc: 93.2647 lam_u 1.4648 unlab loss: 0.2075 unlab acc: 93.8248LR: 0.002000
epoch: 31 train loss: 0.0618 train acc: 97.9317 val loss: 0.0000 val acc: 0.0000 test loss: 0.2238 test acc: 93.1889 lam_u 1.5137 unlab loss: 0.2115 unlab acc: 93.7463LR: 0.002000
epoch: 32 train loss: 0.0612 train acc: 97.9504 val loss: 0.0000 val acc: 0.0000 test loss: 0.2262 test acc: 93.1289 lam_u 1.5625 unlab loss: 0.2140 unlab acc: 93.7046LR: 0.002000
epoch: 33 train loss: 0.0617 train acc: 97.9553 val loss: 0.0000 val acc: 0.0000 test loss: 0.2256 test acc: 93.1377 lam_u 1.6113 unlab loss: 0.2141 unlab acc: 93.6654LR: 0.002000
epoch: 34 train loss: 0.0620 train acc: 97.9570 val loss: 0.0000 val acc: 0.0000 test loss: 0.2260 test acc: 93.0723 lam_u 1.6601 unlab loss: 0.2147 unlab acc: 93.6061LR: 0.002000
epoch: 35 train loss: 0.0606 train acc: 97.9962 val loss: 0.0000 val acc: 0.0000 test loss: 0.2292 test acc: 93.0058 lam_u 1.7090 unlab loss: 0.2201 unlab acc: 93.4868LR: 0.002000
epoch: 36 train loss: 0.0598 train acc: 98.0054 val loss: 0.0000 val acc: 0.0000 test loss: 0.2341 test acc: 92.8368 lam_u 1.7578 unlab loss: 0.2239 unlab acc: 93.3408LR: 0.002000
epoch: 37 train loss: 0.0593 train acc: 98.0257 val loss: 0.0000 val acc: 0.0000 test loss: 0.2369 test acc: 92.7735 lam_u 1.8066 unlab loss: 0.2294 unlab acc: 93.2187LR: 0.002000
epoch: 38 train loss: 0.0603 train acc: 98.0105 val loss: 0.0000 val acc: 0.0000 test loss: 0.2399 test acc: 92.6710 lam_u 1.8554 unlab loss: 0.2315 unlab acc: 93.1397LR: 0.002000
epoch: 39 train loss: 0.0599 train acc: 98.0241 val loss: 0.0000 val acc: 0.0000 test loss: 0.2441 test acc: 92.5491 lam_u 1.9043 unlab loss: 0.2379 unlab acc: 92.9518LR: 0.002000
epoch: 40 train loss: 0.0596 train acc: 98.0430 val loss: 0.0000 val acc: 0.0000 test loss: 0.2469 test acc: 92.4477 lam_u 1.9531 unlab loss: 0.2438 unlab acc: 92.7523LR: 0.002000
epoch: 41 train loss: 0.0593 train acc: 98.0430 val loss: 0.0000 val acc: 0.0000 test loss: 0.2495 test acc: 92.3429 lam_u 2.0019 unlab loss: 0.2483 unlab acc: 92.5762LR: 0.002000
epoch: 42 train loss: 0.0600 train acc: 98.0434 val loss: 0.0000 val acc: 0.0000 test loss: 0.2488 test acc: 92.3798 lam_u 2.0508 unlab loss: 0.2489 unlab acc: 92.6247LR: 0.002000
epoch: 43 train loss: 0.0607 train acc: 98.0395 val loss: 0.0000 val acc: 0.0000 test loss: 0.2553 test acc: 92.1687 lam_u 2.0996 unlab loss: 0.2578 unlab acc: 92.2518LR: 0.002000
epoch: 44 train loss: 0.0596 train acc: 98.0493 val loss: 0.0000 val acc: 0.0000 test loss: 0.2547 test acc: 92.2061 lam_u 2.1484 unlab loss: 0.2580 unlab acc: 92.2775LR: 0.002000
epoch: 45 train loss: 0.0598 train acc: 98.0484 val loss: 0.0000 val acc: 0.0000 test loss: 0.2609 test acc: 92.0613 lam_u 2.1972 unlab loss: 0.2665 unlab acc: 92.0929LR: 0.002000
epoch: 46 train loss: 0.0597 train acc: 98.0559 val loss: 0.0000 val acc: 0.0000 test loss: 0.2629 test acc: 92.0631 lam_u 2.2461 unlab loss: 0.2704 unlab acc: 91.9938LR: 0.002000
epoch: 47 train loss: 0.0603 train acc: 98.0540 val loss: 0.0000 val acc: 0.0000 test loss: 0.2643 test acc: 91.9879 lam_u 2.2949 unlab loss: 0.2734 unlab acc: 91.8582LR: 0.002000
epoch: 48 train loss: 0.0601 train acc: 98.0605 val loss: 0.0000 val acc: 0.0000 test loss: 0.2671 test acc: 91.9304 lam_u 2.3437 unlab loss: 0.2753 unlab acc: 91.9009LR: 0.002000
epoch: 49 train loss: 0.0617 train acc: 98.0556 val loss: 0.0000 val acc: 0.0000 test loss: 0.2682 test acc: 91.8498 lam_u 2.3926 unlab loss: 0.2769 unlab acc: 91.8272LR: 0.002000
epoch: 50 train loss: 0.0616 train acc: 98.0508 val loss: 0.0000 val acc: 0.0000 test loss: 0.2658 test acc: 91.9625 lam_u 2.4414 unlab loss: 0.2756 unlab acc: 91.8970LR: 0.002000
epoch: 51 train loss: 0.0617 train acc: 98.0662 val loss: 0.0000 val acc: 0.0000 test loss: 0.2693 test acc: 91.8213 lam_u 2.4902 unlab loss: 0.2817 unlab acc: 91.6536LR: 0.002000
epoch: 52 train loss: 0.0621 train acc: 98.0552 val loss: 0.0000 val acc: 0.0000 test loss: 0.2695 test acc: 91.9105 lam_u 2.5390 unlab loss: 0.2842 unlab acc: 91.6526LR: 0.002000
epoch: 53 train loss: 0.0614 train acc: 98.0515 val loss: 0.0000 val acc: 0.0000 test loss: 0.2699 test acc: 91.8277 lam_u 2.5879 unlab loss: 0.2825 unlab acc: 91.6959LR: 0.002000
epoch: 54 train loss: 0.0618 train acc: 98.0502 val loss: 0.0000 val acc: 0.0000 test loss: 0.2696 test acc: 91.9283 lam_u 2.6367 unlab loss: 0.2803 unlab acc: 91.8273LR: 0.002000
epoch: 55 train loss: 0.0622 train acc: 98.0416 val loss: 0.0000 val acc: 0.0000 test loss: 0.2691 test acc: 91.9103 lam_u 2.6855 unlab loss: 0.2798 unlab acc: 91.8219LR: 0.002000
epoch: 56 train loss: 0.0621 train acc: 98.0412 val loss: 0.0000 val acc: 0.0000 test loss: 0.2621 test acc: 92.0880 lam_u 2.7344 unlab loss: 0.2725 unlab acc: 91.9968LR: 0.002000
epoch: 57 train loss: 0.0621 train acc: 98.0488 val loss: 0.0000 val acc: 0.0000 test loss: 0.2674 test acc: 92.0159 lam_u 2.7832 unlab loss: 0.2768 unlab acc: 91.9669LR: 0.002000
epoch: 58 train loss: 0.0630 train acc: 98.0413 val loss: 0.0000 val acc: 0.0000 test loss: 0.2702 test acc: 91.9127 lam_u 2.8320 unlab loss: 0.2785 unlab acc: 91.8710LR: 0.002000
epoch: 59 train loss: 0.0638 train acc: 98.0334 val loss: 0.0000 val acc: 0.0000 test loss: 0.2699 test acc: 91.8888 lam_u 2.8808 unlab loss: 0.2808 unlab acc: 91.7778LR: 0.002000
epoch: 60 train loss: 0.0637 train acc: 98.0469 val loss: 0.0000 val acc: 0.0000 test loss: 0.2706 test acc: 91.8759 lam_u 2.9297 unlab loss: 0.2814 unlab acc: 91.7976LR: 0.002000
epoch: 61 train loss: 0.0633 train acc: 98.0440 val loss: 0.0000 val acc: 0.0000 test loss: 0.2687 test acc: 91.8684 lam_u 2.9785 unlab loss: 0.2787 unlab acc: 91.8000LR: 0.002000
epoch: 62 train loss: 0.0646 train acc: 98.0328 val loss: 0.0000 val acc: 0.0000 test loss: 0.2689 test acc: 91.9127 lam_u 3.0273 unlab loss: 0.2770 unlab acc: 91.8949LR: 0.002000
epoch: 63 train loss: 0.0639 train acc: 98.0392 val loss: 0.0000 val acc: 0.0000 test loss: 0.2733 test acc: 91.8194 lam_u 3.0762 unlab loss: 0.2843 unlab acc: 91.7035LR: 0.002000
epoch: 64 train loss: 0.0630 train acc: 98.0439 val loss: 0.0000 val acc: 0.0000 test loss: 0.2702 test acc: 91.9411 lam_u 3.1250 unlab loss: 0.2796 unlab acc: 91.9151LR: 0.002000
epoch: 65 train loss: 0.0645 train acc: 98.0315 val loss: 0.0000 val acc: 0.0000 test loss: 0.2717 test acc: 91.9203 lam_u 3.1738 unlab loss: 0.2836 unlab acc: 91.8373LR: 0.002000
epoch: 66 train loss: 0.0651 train acc: 98.0333 val loss: 0.0000 val acc: 0.0000 test loss: 0.2714 test acc: 91.9499 lam_u 3.2226 unlab loss: 0.2823 unlab acc: 91.8412LR: 0.002000
epoch: 67 train loss: 0.0650 train acc: 98.0375 val loss: 0.0000 val acc: 0.0000 test loss: 0.2752 test acc: 91.8027 lam_u 3.2715 unlab loss: 0.2861 unlab acc: 91.7338LR: 0.002000
epoch: 68 train loss: 0.0654 train acc: 98.0343 val loss: 0.0000 val acc: 0.0000 test loss: 0.2731 test acc: 91.8606 lam_u 3.3203 unlab loss: 0.2865 unlab acc: 91.6775LR: 0.002000
epoch: 69 train loss: 0.0645 train acc: 98.0394 val loss: 0.0000 val acc: 0.0000 test loss: 0.2764 test acc: 91.7664 lam_u 3.3691 unlab loss: 0.2901 unlab acc: 91.5316LR: 0.002000
epoch: 70 train loss: 0.0655 train acc: 98.0395 val loss: 0.0000 val acc: 0.0000 test loss: 0.2782 test acc: 91.7067 lam_u 3.4179 unlab loss: 0.2908 unlab acc: 91.4387LR: 0.002000
epoch: 71 train loss: 0.0656 train acc: 98.0220 val loss: 0.0000 val acc: 0.0000 test loss: 0.2791 test acc: 91.6337 lam_u 3.4668 unlab loss: 0.2934 unlab acc: 91.3441LR: 0.002000
epoch: 72 train loss: 0.0674 train acc: 97.9975 val loss: 0.0000 val acc: 0.0000 test loss: 0.2821 test acc: 91.7335 lam_u 3.5156 unlab loss: 0.2926 unlab acc: 91.6817LR: 0.002000
epoch: 73 train loss: 0.0665 train acc: 98.0067 val loss: 0.0000 val acc: 0.0000 test loss: 0.2772 test acc: 91.8124 lam_u 3.5644 unlab loss: 0.2895 unlab acc: 91.6580LR: 0.002000
epoch: 74 train loss: 0.0663 train acc: 98.0126 val loss: 0.0000 val acc: 0.0000 test loss: 0.2793 test acc: 91.8153 lam_u 3.6133 unlab loss: 0.2898 unlab acc: 91.7413LR: 0.002000
epoch: 75 train loss: 0.0666 train acc: 98.0175 val loss: 0.0000 val acc: 0.0000 test loss: 0.2749 test acc: 91.8571 lam_u 3.6621 unlab loss: 0.2899 unlab acc: 91.5849LR: 0.002000
epoch: 76 train loss: 0.0672 train acc: 98.0325 val loss: 0.0000 val acc: 0.0000 test loss: 0.2806 test acc: 91.8422 lam_u 3.7109 unlab loss: 0.2976 unlab acc: 91.5970LR: 0.002000
epoch: 77 train loss: 0.0674 train acc: 98.0163 val loss: 0.0000 val acc: 0.0000 test loss: 0.2814 test acc: 91.7152 lam_u 3.7597 unlab loss: 0.2931 unlab acc: 91.5697LR: 0.002000
epoch: 78 train loss: 0.0672 train acc: 98.0096 val loss: 0.0000 val acc: 0.0000 test loss: 0.2807 test acc: 91.6884 lam_u 3.8086 unlab loss: 0.2921 unlab acc: 91.5839LR: 0.002000
epoch: 79 train loss: 0.0676 train acc: 97.9973 val loss: 0.0000 val acc: 0.0000 test loss: 0.2779 test acc: 91.7406 lam_u 3.8574 unlab loss: 0.2893 unlab acc: 91.6058LR: 0.002000
epoch: 80 train loss: 0.0669 train acc: 98.0288 val loss: 0.0000 val acc: 0.0000 test loss: 0.2835 test acc: 91.5945 lam_u 3.9062 unlab loss: 0.2969 unlab acc: 91.4016LR: 0.002000
epoch: 81 train loss: 0.0676 train acc: 97.9994 val loss: 0.0000 val acc: 0.0000 test loss: 0.2747 test acc: 91.8214 lam_u 3.9551 unlab loss: 0.2884 unlab acc: 91.6778LR: 0.002000
epoch: 82 train loss: 0.0668 train acc: 98.0072 val loss: 0.0000 val acc: 0.0000 test loss: 0.2832 test acc: 91.5234 lam_u 4.0039 unlab loss: 0.3011 unlab acc: 91.2052LR: 0.002000
epoch: 83 train loss: 0.0670 train acc: 98.0226 val loss: 0.0000 val acc: 0.0000 test loss: 0.2821 test acc: 91.7103 lam_u 4.0527 unlab loss: 0.2948 unlab acc: 91.6011LR: 0.002000
epoch: 84 train loss: 0.0690 train acc: 97.9937 val loss: 0.0000 val acc: 0.0000 test loss: 0.2827 test acc: 91.6146 lam_u 4.1015 unlab loss: 0.2962 unlab acc: 91.4354LR: 0.002000
epoch: 85 train loss: 0.0690 train acc: 97.9932 val loss: 0.0000 val acc: 0.0000 test loss: 0.2826 test acc: 91.7055 lam_u 4.1504 unlab loss: 0.2975 unlab acc: 91.5157LR: 0.002000
epoch: 86 train loss: 0.0686 train acc: 98.0102 val loss: 0.0000 val acc: 0.0000 test loss: 0.2802 test acc: 91.7366 lam_u 4.1992 unlab loss: 0.2918 unlab acc: 91.6155LR: 0.002000
epoch: 87 train loss: 0.0682 train acc: 98.0145 val loss: 0.0000 val acc: 0.0000 test loss: 0.2864 test acc: 91.5697 lam_u 4.2480 unlab loss: 0.3013 unlab acc: 91.3149LR: 0.002000
epoch: 88 train loss: 0.0678 train acc: 98.0134 val loss: 0.0000 val acc: 0.0000 test loss: 0.2858 test acc: 91.6859 lam_u 4.2969 unlab loss: 0.3016 unlab acc: 91.4684LR: 0.002000
epoch: 89 train loss: 0.0673 train acc: 97.9896 val loss: 0.0000 val acc: 0.0000 test loss: 0.2813 test acc: 91.7764 lam_u 4.3457 unlab loss: 0.2957 unlab acc: 91.6415LR: 0.002000
epoch: 90 train loss: 0.0688 train acc: 98.0038 val loss: 0.0000 val acc: 0.0000 test loss: 0.2847 test acc: 91.6482 lam_u 4.3945 unlab loss: 0.3034 unlab acc: 91.3182LR: 0.002000
epoch: 91 train loss: 0.0686 train acc: 97.9947 val loss: 0.0000 val acc: 0.0000 test loss: 0.2870 test acc: 91.6716 lam_u 4.4433 unlab loss: 0.3045 unlab acc: 91.3407LR: 0.002000
epoch: 92 train loss: 0.0671 train acc: 97.9890 val loss: 0.0000 val acc: 0.0000 test loss: 0.2822 test acc: 91.7457 lam_u 4.4922 unlab loss: 0.3010 unlab acc: 91.4570LR: 0.002000
epoch: 93 train loss: 0.0680 train acc: 97.9956 val loss: 0.0000 val acc: 0.0000 test loss: 0.2783 test acc: 91.8651 lam_u 4.5410 unlab loss: 0.2919 unlab acc: 91.7072LR: 0.002000
epoch: 94 train loss: 0.0686 train acc: 97.9893 val loss: 0.0000 val acc: 0.0000 test loss: 0.2884 test acc: 91.5265 lam_u 4.5898 unlab loss: 0.3085 unlab acc: 91.0772LR: 0.002000
epoch: 95 train loss: 0.0673 train acc: 98.0138 val loss: 0.0000 val acc: 0.0000 test loss: 0.2862 test acc: 91.5957 lam_u 4.6387 unlab loss: 0.3008 unlab acc: 91.3569LR: 0.002000
epoch: 96 train loss: 0.0691 train acc: 97.9914 val loss: 0.0000 val acc: 0.0000 test loss: 0.2884 test acc: 91.4865 lam_u 4.6875 unlab loss: 0.3088 unlab acc: 90.9753LR: 0.002000
epoch: 97 train loss: 0.0676 train acc: 98.0181 val loss: 0.0000 val acc: 0.0000 test loss: 0.2854 test acc: 91.6304 lam_u 4.7363 unlab loss: 0.3010 unlab acc: 91.4241LR: 0.002000
epoch: 98 train loss: 0.0680 train acc: 98.0097 val loss: 0.0000 val acc: 0.0000 test loss: 0.2910 test acc: 91.4060 lam_u 4.7851 unlab loss: 0.3084 unlab acc: 91.0265LR: 0.002000
epoch: 99 train loss: 0.0694 train acc: 97.9643 val loss: 0.0000 val acc: 0.0000 test loss: 0.2868 test acc: 91.4850 lam_u 4.8340 unlab loss: 0.3043 unlab acc: 91.0681LR: 0.002000
epoch: 100 train loss: 0.0676 train acc: 97.9927 val loss: 0.0000 val acc: 0.0000 test loss: 0.2883 test acc: 91.5928 lam_u 4.8828 unlab loss: 0.3043 unlab acc: 91.2590LR: 0.002000
epoch: 101 train loss: 0.0687 train acc: 97.9819 val loss: 0.0000 val acc: 0.0000 test loss: 0.2924 test acc: 91.4331 lam_u 4.9316 unlab loss: 0.3104 unlab acc: 91.0340LR: 0.002000
epoch: 102 train loss: 0.0682 train acc: 97.9865 val loss: 0.0000 val acc: 0.0000 test loss: 0.2959 test acc: 91.3876 lam_u 4.9804 unlab loss: 0.3158 unlab acc: 90.9489LR: 0.002000
epoch: 103 train loss: 0.0675 train acc: 97.9791 val loss: 0.0000 val acc: 0.0000 test loss: 0.2962 test acc: 91.2628 lam_u 5.0293 unlab loss: 0.3135 unlab acc: 90.9022LR: 0.002000
epoch: 104 train loss: 0.0676 train acc: 97.9860 val loss: 0.0000 val acc: 0.0000 test loss: 0.2886 test acc: 91.5311 lam_u 5.0781 unlab loss: 0.3070 unlab acc: 91.1956LR: 0.002000
epoch: 105 train loss: 0.0702 train acc: 97.9797 val loss: 0.0000 val acc: 0.0000 test loss: 0.2975 test acc: 91.1944 lam_u 5.1269 unlab loss: 0.3231 unlab acc: 90.4765LR: 0.002000
epoch: 106 train loss: 0.0691 train acc: 97.9683 val loss: 0.0000 val acc: 0.0000 test loss: 0.2885 test acc: 91.5555 lam_u 5.1758 unlab loss: 0.3088 unlab acc: 91.1821LR: 0.002000
epoch: 107 train loss: 0.0695 train acc: 97.9632 val loss: 0.0000 val acc: 0.0000 test loss: 0.2978 test acc: 91.3472 lam_u 5.2246 unlab loss: 0.3237 unlab acc: 90.7212LR: 0.002000
epoch: 108 train loss: 0.0714 train acc: 97.9639 val loss: 0.0000 val acc: 0.0000 test loss: 0.2974 test acc: 91.3043 lam_u 5.2734 unlab loss: 0.3232 unlab acc: 90.5332LR: 0.002000
epoch: 109 train loss: 0.0713 train acc: 97.9431 val loss: 0.0000 val acc: 0.0000 test loss: 0.2924 test acc: 91.4159 lam_u 5.3222 unlab loss: 0.3174 unlab acc: 90.6234LR: 0.002000
epoch: 110 train loss: 0.0690 train acc: 97.9749 val loss: 0.0000 val acc: 0.0000 test loss: 0.2960 test acc: 91.4492 lam_u 5.3711 unlab loss: 0.3146 unlab acc: 91.0577LR: 0.002000
epoch: 111 train loss: 0.0696 train acc: 97.9918 val loss: 0.0000 val acc: 0.0000 test loss: 0.2971 test acc: 91.5183 lam_u 5.4199 unlab loss: 0.3141 unlab acc: 91.1660LR: 0.002000
epoch: 112 train loss: 0.0695 train acc: 97.9869 val loss: 0.0000 val acc: 0.0000 test loss: 0.2989 test acc: 91.2415 lam_u 5.4687 unlab loss: 0.3210 unlab acc: 90.4993LR: 0.002000
epoch: 113 train loss: 0.0696 train acc: 97.9735 val loss: 0.0000 val acc: 0.0000 test loss: 0.2944 test acc: 91.5143 lam_u 5.5176 unlab loss: 0.3100 unlab acc: 91.2701LR: 0.002000
epoch: 114 train loss: 0.0710 train acc: 97.9468 val loss: 0.0000 val acc: 0.0000 test loss: 0.2982 test acc: 91.3674 lam_u 5.5664 unlab loss: 0.3195 unlab acc: 90.9049LR: 0.002000
epoch: 115 train loss: 0.0684 train acc: 97.9803 val loss: 0.0000 val acc: 0.0000 test loss: 0.3000 test acc: 91.2720 lam_u 5.6152 unlab loss: 0.3208 unlab acc: 90.7804LR: 0.002000
epoch: 116 train loss: 0.0691 train acc: 97.9782 val loss: 0.0000 val acc: 0.0000 test loss: 0.2989 test acc: 91.4082 lam_u 5.6640 unlab loss: 0.3171 unlab acc: 91.1076LR: 0.002000
epoch: 117 train loss: 0.0702 train acc: 97.9628 val loss: 0.0000 val acc: 0.0000 test loss: 0.3010 test acc: 91.2653 lam_u 5.7129 unlab loss: 0.3181 unlab acc: 90.9750LR: 0.002000
epoch: 118 train loss: 0.0694 train acc: 97.9569 val loss: 0.0000 val acc: 0.0000 test loss: 0.2968 test acc: 91.3153 lam_u 5.7617 unlab loss: 0.3176 unlab acc: 90.9407LR: 0.002000
epoch: 119 train loss: 0.0699 train acc: 97.9555 val loss: 0.0000 val acc: 0.0000 test loss: 0.3079 test acc: 91.0156 lam_u 5.8105 unlab loss: 0.3301 unlab acc: 90.5000LR: 0.002000
epoch: 120 train loss: 0.0697 train acc: 97.9666 val loss: 0.0000 val acc: 0.0000 test loss: 0.3002 test acc: 91.1940 lam_u 5.8594 unlab loss: 0.3210 unlab acc: 90.7201LR: 0.002000
epoch: 121 train loss: 0.0711 train acc: 97.9401 val loss: 0.0000 val acc: 0.0000 test loss: 0.3053 test acc: 91.1328 lam_u 5.9082 unlab loss: 0.3274 unlab acc: 90.6670LR: 0.002000
epoch: 122 train loss: 0.0690 train acc: 97.9540 val loss: 0.0000 val acc: 0.0000 test loss: 0.3117 test acc: 90.8756 lam_u 5.9570 unlab loss: 0.3424 unlab acc: 89.9756LR: 0.002000
epoch: 123 train loss: 0.0704 train acc: 97.9342 val loss: 0.0000 val acc: 0.0000 test loss: 0.3089 test acc: 90.9874 lam_u 6.0058 unlab loss: 0.3324 unlab acc: 90.4129LR: 0.002000
epoch: 124 train loss: 0.0708 train acc: 97.9318 val loss: 0.0000 val acc: 0.0000 test loss: 0.2945 test acc: 91.4230 lam_u 6.0547 unlab loss: 0.3153 unlab acc: 91.0293LR: 0.002000
epoch: 125 train loss: 0.0698 train acc: 97.9281 val loss: 0.0000 val acc: 0.0000 test loss: 0.2966 test acc: 91.2256 lam_u 6.1035 unlab loss: 0.3199 unlab acc: 90.6234LR: 0.002000
epoch: 126 train loss: 0.0694 train acc: 97.9409 val loss: 0.0000 val acc: 0.0000 test loss: 0.3065 test acc: 91.0434 lam_u 6.1523 unlab loss: 0.3334 unlab acc: 90.4513LR: 0.002000
epoch: 127 train loss: 0.0707 train acc: 97.9135 val loss: 0.0000 val acc: 0.0000 test loss: 0.3060 test acc: 91.0437 lam_u 6.2012 unlab loss: 0.3330 unlab acc: 90.3877LR: 0.002000
epoch: 128 train loss: 0.0696 train acc: 97.9318 val loss: 0.0000 val acc: 0.0000 test loss: 0.3034 test acc: 91.2527 lam_u 6.2500 unlab loss: 0.3272 unlab acc: 90.7637LR: 0.002000
epoch: 129 train loss: 0.0729 train acc: 97.8921 val loss: 0.0000 val acc: 0.0000 test loss: 0.3048 test acc: 91.1775 lam_u 6.2988 unlab loss: 0.3263 unlab acc: 90.6805LR: 0.002000
epoch: 130 train loss: 0.0702 train acc: 97.9452 val loss: 0.0000 val acc: 0.0000 test loss: 0.3027 test acc: 91.2127 lam_u 6.3476 unlab loss: 0.3265 unlab acc: 90.6951LR: 0.002000
epoch: 131 train loss: 0.0716 train acc: 97.9161 val loss: 0.0000 val acc: 0.0000 test loss: 0.3028 test acc: 91.1682 lam_u 6.3965 unlab loss: 0.3311 unlab acc: 90.4340LR: 0.002000
epoch: 132 train loss: 0.0705 train acc: 97.9403 val loss: 0.0000 val acc: 0.0000 test loss: 0.3063 test acc: 91.2154 lam_u 6.4453 unlab loss: 0.3337 unlab acc: 90.6788LR: 0.002000
epoch: 133 train loss: 0.0730 train acc: 97.8855 val loss: 0.0000 val acc: 0.0000 test loss: 0.3019 test acc: 91.3666 lam_u 6.4941 unlab loss: 0.3226 unlab acc: 91.0723LR: 0.002000
epoch: 134 train loss: 0.0719 train acc: 97.9126 val loss: 0.0000 val acc: 0.0000 test loss: 0.3127 test acc: 90.8280 lam_u 6.5429 unlab loss: 0.3457 unlab acc: 89.6414LR: 0.002000
epoch: 135 train loss: 0.0700 train acc: 97.9201 val loss: 0.0000 val acc: 0.0000 test loss: 0.3083 test acc: 90.9698 lam_u 6.5918 unlab loss: 0.3384 unlab acc: 90.0398LR: 0.002000
epoch: 136 train loss: 0.0717 train acc: 97.9047 val loss: 0.0000 val acc: 0.0000 test loss: 0.3184 test acc: 90.6803 lam_u 6.6406 unlab loss: 0.3524 unlab acc: 89.4466LR: 0.002000
epoch: 137 train loss: 0.0704 train acc: 97.9258 val loss: 0.0000 val acc: 0.0000 test loss: 0.3061 test acc: 91.1133 lam_u 6.6894 unlab loss: 0.3371 unlab acc: 90.1933LR: 0.002000
epoch: 138 train loss: 0.0715 train acc: 97.9162 val loss: 0.0000 val acc: 0.0000 test loss: 0.3093 test acc: 91.0679 lam_u 6.7383 unlab loss: 0.3394 unlab acc: 90.2581LR: 0.002000
epoch: 139 train loss: 0.0725 train acc: 97.9194 val loss: 0.0000 val acc: 0.0000 test loss: 0.3133 test acc: 90.9169 lam_u 6.7871 unlab loss: 0.3444 unlab acc: 89.9652LR: 0.002000
epoch: 140 train loss: 0.0711 train acc: 97.9117 val loss: 0.0000 val acc: 0.0000 test loss: 0.3065 test acc: 91.1368 lam_u 6.8359 unlab loss: 0.3346 unlab acc: 90.4465LR: 0.002000
epoch: 141 train loss: 0.0725 train acc: 97.8828 val loss: 0.0000 val acc: 0.0000 test loss: 0.3006 test acc: 91.2594 lam_u 6.8847 unlab loss: 0.3306 unlab acc: 90.5109LR: 0.002000
epoch: 142 train loss: 0.0731 train acc: 97.8687 val loss: 0.0000 val acc: 0.0000 test loss: 0.3028 test acc: 91.0864 lam_u 6.9336 unlab loss: 0.3284 unlab acc: 90.5276LR: 0.002000
epoch: 143 train loss: 0.0729 train acc: 97.8826 val loss: 0.0000 val acc: 0.0000 test loss: 0.3066 test acc: 91.1812 lam_u 6.9824 unlab loss: 0.3279 unlab acc: 90.8170LR: 0.002000
epoch: 144 train loss: 0.0721 train acc: 97.8959 val loss: 0.0000 val acc: 0.0000 test loss: 0.3018 test acc: 91.3663 lam_u 7.0312 unlab loss: 0.3227 unlab acc: 91.1077LR: 0.002000
epoch: 145 train loss: 0.0726 train acc: 97.8598 val loss: 0.0000 val acc: 0.0000 test loss: 0.2970 test acc: 91.3300 lam_u 7.0801 unlab loss: 0.3178 unlab acc: 91.0516LR: 0.002000
epoch: 146 train loss: 0.0731 train acc: 97.8817 val loss: 0.0000 val acc: 0.0000 test loss: 0.3092 test acc: 91.1174 lam_u 7.1289 unlab loss: 0.3353 unlab acc: 90.6515LR: 0.002000
epoch: 147 train loss: 0.0726 train acc: 97.8866 val loss: 0.0000 val acc: 0.0000 test loss: 0.3017 test acc: 91.3696 lam_u 7.1777 unlab loss: 0.3227 unlab acc: 91.0644LR: 0.002000
epoch: 148 train loss: 0.0718 train acc: 97.8706 val loss: 0.0000 val acc: 0.0000 test loss: 0.3040 test acc: 91.2592 lam_u 7.2265 unlab loss: 0.3249 unlab acc: 90.9487LR: 0.002000
epoch: 149 train loss: 0.0719 train acc: 97.8852 val loss: 0.0000 val acc: 0.0000 test loss: 0.3210 test acc: 90.8134 lam_u 7.2754 unlab loss: 0.3469 unlab acc: 90.2389LR: 0.002000
epoch: 150 train loss: 0.0728 train acc: 97.8683 val loss: 0.0000 val acc: 0.0000 test loss: 0.3109 test acc: 91.0527 lam_u 7.3242 unlab loss: 0.3348 unlab acc: 90.5798LR: 0.002000
epoch: 151 train loss: 0.0713 train acc: 97.8916 val loss: 0.0000 val acc: 0.0000 test loss: 0.3124 test acc: 91.0487 lam_u 7.3730 unlab loss: 0.3327 unlab acc: 90.6310LR: 0.002000
epoch: 152 train loss: 0.0714 train acc: 97.8769 val loss: 0.0000 val acc: 0.0000 test loss: 0.3081 test acc: 91.2028 lam_u 7.4219 unlab loss: 0.3299 unlab acc: 90.7255LR: 0.002000
epoch: 153 train loss: 0.0728 train acc: 97.8554 val loss: 0.0000 val acc: 0.0000 test loss: 0.3040 test acc: 91.2920 lam_u 7.4707 unlab loss: 0.3289 unlab acc: 90.8452LR: 0.002000
epoch: 154 train loss: 0.0723 train acc: 97.8456 val loss: 0.0000 val acc: 0.0000 test loss: 0.3109 test acc: 91.1042 lam_u 7.5195 unlab loss: 0.3292 unlab acc: 90.8582LR: 0.002000
epoch: 155 train loss: 0.0719 train acc: 97.8789 val loss: 0.0000 val acc: 0.0000 test loss: 0.3128 test acc: 90.9397 lam_u 7.5683 unlab loss: 0.3373 unlab acc: 90.4576LR: 0.002000
