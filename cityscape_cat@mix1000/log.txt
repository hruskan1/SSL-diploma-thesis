# Starting at 2023-05-17 19:00:25.035439
with args:
current_count : 0
epochs : 50
kimg : 20000
K : 2
temperature : 0.5
alpha : 0.3
lambda_u : 25.0
rampup_length : 1024
n_labeled : 1000
n_val : 0
batch_size : 4
learning_rate : 0.002
lr_scheduler : False
loss_ewa_coef : 0.98
device : cuda:0
dataset_path : /mnt/personal/hruskan1/CityScapes
mean_teacher_coef : 0.999
out : ./cityscape_cat@mix1000_ll
resume : None
from_yml : None
log_period : 1
save_period : 0
debug : True
seed : 0
weight_decay : 4e-05
model_architecture : {'blocks': [{'type': 'encoder', 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'niters': 2, 'in_ch': 3, 'mid_ch': 64, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'encoder', 'niters': 2, 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'in_ch': 64, 'mid_ch': 128, 'out_ch': 128, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'encoder', 'niters': 2, 'use_kornia': True, 'scale': 0.5, 'interpolation': 'bilinear', 'in_ch': 128, 'mid_ch': 256, 'out_ch': 256, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'bottleneck', 'niters': 3, 'in_ch': 256, 'mid_ch': 512, 'out_ch': 256, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 3, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 512, 'mid_ch': 256, 'out_ch': 128, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 3, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 256, 'mid_ch': 128, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'decoder', 'niters': 2, 'use_kornia': True, 'scale': 2.0, 'interpolation': 'bilinear', 'in_ch': 128, 'mid_ch': 64, 'out_ch': 64, 'conv_kernel': [3, 3], 'conv_stride': [1, 1], 'conv_paddings': [1, 1], 'normalization_type': 'batch'}, {'type': 'classifier', 'in_ch': 64, 'out_ch': 8, 'conv_kernel': [1, 1], 'normalization_type': 'batch'}]}
img_size : [128, 256]
logpath : ./cityscape_cat@mix1000_ll/log.txt
modelpath : ./cityscape_cat@mix1000_ll/model
No resume point provided, will start from scratch!
Creating new network!
    Total params: 8.56M
epoch: 1 train loss: 0.2794 train acc: 91.1939 val loss: 0.0000 val acc: 0.0000 test loss: 0.3145 test acc: 89.8796 lam_u 0.0244 unlab loss: 0.2880 unlab acc: 90.9314LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e1-a90-m.pt
epoch: 2 train loss: 0.2041 train acc: 93.4920 val loss: 0.0000 val acc: 0.0000 test loss: 0.2483 test acc: 91.9801 lam_u 0.0488 unlab loss: 0.2248 unlab acc: 92.7867LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e2-a92-m.pt
epoch: 3 train loss: 0.1670 train acc: 94.6685 val loss: 0.0000 val acc: 0.0000 test loss: 0.2176 test acc: 92.9129 lam_u 0.0732 unlab loss: 0.1956 unlab acc: 93.6638LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e3-a93-m.pt
epoch: 4 train loss: 0.1446 train acc: 95.3354 val loss: 0.0000 val acc: 0.0000 test loss: 0.2011 test acc: 93.4355 lam_u 0.0977 unlab loss: 0.1810 unlab acc: 94.0913LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e4-a93-m.pt
epoch: 5 train loss: 0.1294 train acc: 95.7784 val loss: 0.0000 val acc: 0.0000 test loss: 0.1902 test acc: 93.7301 lam_u 0.1221 unlab loss: 0.1732 unlab acc: 94.3370LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e5-a94-m.pt
epoch: 6 train loss: 0.1183 train acc: 96.1145 val loss: 0.0000 val acc: 0.0000 test loss: 0.1867 test acc: 93.8529 lam_u 0.1465 unlab loss: 0.1677 unlab acc: 94.5026LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e6-a94-m.pt
epoch: 7 train loss: 0.1109 train acc: 96.3262 val loss: 0.0000 val acc: 0.0000 test loss: 0.1822 test acc: 94.0245 lam_u 0.1709 unlab loss: 0.1661 unlab acc: 94.5727LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e7-a94-m.pt
epoch: 8 train loss: 0.1048 train acc: 96.5000 val loss: 0.0000 val acc: 0.0000 test loss: 0.1818 test acc: 94.0340 lam_u 0.1953 unlab loss: 0.1640 unlab acc: 94.6506LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e8-a94-m.pt
epoch: 9 train loss: 0.0999 train acc: 96.6256 val loss: 0.0000 val acc: 0.0000 test loss: 0.1792 test acc: 94.1153 lam_u 0.2197 unlab loss: 0.1628 unlab acc: 94.6935LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e9-a94-m.pt
epoch: 10 train loss: 0.0972 train acc: 96.7040 val loss: 0.0000 val acc: 0.0000 test loss: 0.1791 test acc: 94.1266 lam_u 0.2441 unlab loss: 0.1610 unlab acc: 94.7376LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e10-a94-m.pt
epoch: 11 train loss: 0.0940 train acc: 96.7810 val loss: 0.0000 val acc: 0.0000 test loss: 0.1790 test acc: 94.1395 lam_u 0.2685 unlab loss: 0.1616 unlab acc: 94.7313LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e11-a94-m.pt
epoch: 12 train loss: 0.0912 train acc: 96.8690 val loss: 0.0000 val acc: 0.0000 test loss: 0.1797 test acc: 94.1375 lam_u 0.2930 unlab loss: 0.1611 unlab acc: 94.7740LR: 0.002000
epoch: 13 train loss: 0.0897 train acc: 96.9232 val loss: 0.0000 val acc: 0.0000 test loss: 0.1795 test acc: 94.1460 lam_u 0.3174 unlab loss: 0.1618 unlab acc: 94.7696LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e13-a94-m.pt
epoch: 14 train loss: 0.0867 train acc: 96.9885 val loss: 0.0000 val acc: 0.0000 test loss: 0.1795 test acc: 94.1603 lam_u 0.3418 unlab loss: 0.1622 unlab acc: 94.7840LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e14-a94-m.pt
epoch: 15 train loss: 0.0857 train acc: 97.0345 val loss: 0.0000 val acc: 0.0000 test loss: 0.1799 test acc: 94.1657 lam_u 0.3662 unlab loss: 0.1617 unlab acc: 94.8070LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e15-a94-m.pt
epoch: 16 train loss: 0.0839 train acc: 97.0934 val loss: 0.0000 val acc: 0.0000 test loss: 0.1777 test acc: 94.2202 lam_u 0.3906 unlab loss: 0.1611 unlab acc: 94.8300LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e16-a94-m.pt
epoch: 17 train loss: 0.0871 train acc: 97.0521 val loss: 0.0000 val acc: 0.0000 test loss: 0.1794 test acc: 94.1567 lam_u 0.4150 unlab loss: 0.1627 unlab acc: 94.7719LR: 0.002000
epoch: 18 train loss: 0.0821 train acc: 97.1543 val loss: 0.0000 val acc: 0.0000 test loss: 0.1784 test acc: 94.2081 lam_u 0.4394 unlab loss: 0.1621 unlab acc: 94.8177LR: 0.002000
epoch: 19 train loss: 0.0812 train acc: 97.1798 val loss: 0.0000 val acc: 0.0000 test loss: 0.1797 test acc: 94.1944 lam_u 0.4639 unlab loss: 0.1617 unlab acc: 94.8296LR: 0.002000
epoch: 20 train loss: 0.0809 train acc: 97.1926 val loss: 0.0000 val acc: 0.0000 test loss: 0.1810 test acc: 94.1481 lam_u 0.4883 unlab loss: 0.1626 unlab acc: 94.8129LR: 0.002000
epoch: 21 train loss: 0.0788 train acc: 97.2553 val loss: 0.0000 val acc: 0.0000 test loss: 0.1780 test acc: 94.2534 lam_u 0.5127 unlab loss: 0.1623 unlab acc: 94.8451LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e21-a94-m.pt
epoch: 22 train loss: 0.0776 train acc: 97.2781 val loss: 0.0000 val acc: 0.0000 test loss: 0.1770 test acc: 94.2758 lam_u 0.5371 unlab loss: 0.1620 unlab acc: 94.8461LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e22-a94-m.pt
epoch: 23 train loss: 0.0792 train acc: 97.2647 val loss: 0.0000 val acc: 0.0000 test loss: 0.1779 test acc: 94.2552 lam_u 0.5615 unlab loss: 0.1622 unlab acc: 94.8275LR: 0.002000
epoch: 24 train loss: 0.0783 train acc: 97.2982 val loss: 0.0000 val acc: 0.0000 test loss: 0.1798 test acc: 94.2344 lam_u 0.5859 unlab loss: 0.1629 unlab acc: 94.8316LR: 0.002000
epoch: 25 train loss: 0.0764 train acc: 97.3184 val loss: 0.0000 val acc: 0.0000 test loss: 0.1781 test acc: 94.2550 lam_u 0.6103 unlab loss: 0.1611 unlab acc: 94.8716LR: 0.002000
epoch: 26 train loss: 0.0760 train acc: 97.3460 val loss: 0.0000 val acc: 0.0000 test loss: 0.1812 test acc: 94.2113 lam_u 0.6348 unlab loss: 0.1630 unlab acc: 94.8360LR: 0.002000
epoch: 27 train loss: 0.0761 train acc: 97.3699 val loss: 0.0000 val acc: 0.0000 test loss: 0.1791 test acc: 94.2491 lam_u 0.6592 unlab loss: 0.1619 unlab acc: 94.8585LR: 0.002000
epoch: 28 train loss: 0.0751 train acc: 97.3789 val loss: 0.0000 val acc: 0.0000 test loss: 0.1783 test acc: 94.2563 lam_u 0.6836 unlab loss: 0.1619 unlab acc: 94.8729LR: 0.002000
epoch: 29 train loss: 0.0751 train acc: 97.3963 val loss: 0.0000 val acc: 0.0000 test loss: 0.1780 test acc: 94.2903 lam_u 0.7080 unlab loss: 0.1635 unlab acc: 94.8432LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e29-a94-m.pt
epoch: 30 train loss: 0.0732 train acc: 97.4355 val loss: 0.0000 val acc: 0.0000 test loss: 0.1789 test acc: 94.2745 lam_u 0.7324 unlab loss: 0.1637 unlab acc: 94.8371LR: 0.002000
epoch: 31 train loss: 0.0733 train acc: 97.4616 val loss: 0.0000 val acc: 0.0000 test loss: 0.1797 test acc: 94.2965 lam_u 0.7568 unlab loss: 0.1648 unlab acc: 94.8502LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e31-a94-m.pt
epoch: 32 train loss: 0.0722 train acc: 97.4664 val loss: 0.0000 val acc: 0.0000 test loss: 0.1779 test acc: 94.3248 lam_u 0.7812 unlab loss: 0.1643 unlab acc: 94.8376LR: 0.002000
# Saving Model : ./cityscape_cat@mix1000_ll/model-e32-a94-m.pt
epoch: 33 train loss: 0.0721 train acc: 97.4912 val loss: 0.0000 val acc: 0.0000 test loss: 0.1791 test acc: 94.3131 lam_u 0.8057 unlab loss: 0.1644 unlab acc: 94.8336LR: 0.002000
epoch: 34 train loss: 0.0725 train acc: 97.4649 val loss: 0.0000 val acc: 0.0000 test loss: 0.1794 test acc: 94.2477 lam_u 0.8301 unlab loss: 0.1645 unlab acc: 94.8247LR: 0.002000
epoch: 35 train loss: 0.0738 train acc: 97.4952 val loss: 0.0000 val acc: 0.0000 test loss: 0.1789 test acc: 94.3035 lam_u 0.8545 unlab loss: 0.1655 unlab acc: 94.8182LR: 0.002000
epoch: 36 train loss: 0.0705 train acc: 97.5262 val loss: 0.0000 val acc: 0.0000 test loss: 0.1808 test acc: 94.2692 lam_u 0.8789 unlab loss: 0.1650 unlab acc: 94.8539LR: 0.002000
epoch: 37 train loss: 0.0704 train acc: 97.5259 val loss: 0.0000 val acc: 0.0000 test loss: 0.1799 test acc: 94.2818 lam_u 0.9033 unlab loss: 0.1645 unlab acc: 94.8395LR: 0.002000
epoch: 38 train loss: 0.0699 train acc: 97.5617 val loss: 0.0000 val acc: 0.0000 test loss: 0.1816 test acc: 94.2520 lam_u 0.9277 unlab loss: 0.1655 unlab acc: 94.8477LR: 0.002000
epoch: 39 train loss: 0.0697 train acc: 97.5367 val loss: 0.0000 val acc: 0.0000 test loss: 0.1805 test acc: 94.2818 lam_u 0.9521 unlab loss: 0.1663 unlab acc: 94.8206LR: 0.002000
epoch: 40 train loss: 0.0734 train acc: 97.5292 val loss: 0.0000 val acc: 0.0000 test loss: 0.1789 test acc: 94.2766 lam_u 0.9766 unlab loss: 0.1644 unlab acc: 94.8351LR: 0.002000
epoch: 41 train loss: 0.0706 train acc: 97.5671 val loss: 0.0000 val acc: 0.0000 test loss: 0.1808 test acc: 94.2768 lam_u 1.0010 unlab loss: 0.1656 unlab acc: 94.8454LR: 0.002000
epoch: 42 train loss: 0.0696 train acc: 97.5860 val loss: 0.0000 val acc: 0.0000 test loss: 0.1805 test acc: 94.2671 lam_u 1.0254 unlab loss: 0.1656 unlab acc: 94.8327LR: 0.002000
epoch: 43 train loss: 0.0701 train acc: 97.5875 val loss: 0.0000 val acc: 0.0000 test loss: 0.1806 test acc: 94.2841 lam_u 1.0498 unlab loss: 0.1666 unlab acc: 94.8117LR: 0.002000
epoch: 44 train loss: 0.0706 train acc: 97.5836 val loss: 0.0000 val acc: 0.0000 test loss: 0.1797 test acc: 94.3101 lam_u 1.0742 unlab loss: 0.1660 unlab acc: 94.8253LR: 0.002000
epoch: 45 train loss: 0.0674 train acc: 97.6433 val loss: 0.0000 val acc: 0.0000 test loss: 0.1803 test acc: 94.2986 lam_u 1.0986 unlab loss: 0.1658 unlab acc: 94.8416LR: 0.002000
epoch: 46 train loss: 0.0695 train acc: 97.6042 val loss: 0.0000 val acc: 0.0000 test loss: 0.1817 test acc: 94.2788 lam_u 1.1230 unlab loss: 0.1662 unlab acc: 94.8309LR: 0.002000
epoch: 47 train loss: 0.0675 train acc: 97.6352 val loss: 0.0000 val acc: 0.0000 test loss: 0.1832 test acc: 94.2503 lam_u 1.1475 unlab loss: 0.1691 unlab acc: 94.7864LR: 0.002000
epoch: 48 train loss: 0.0686 train acc: 97.6283 val loss: 0.0000 val acc: 0.0000 test loss: 0.1824 test acc: 94.2195 lam_u 1.1719 unlab loss: 0.1682 unlab acc: 94.7749LR: 0.002000
epoch: 49 train loss: 0.0664 train acc: 97.6580 val loss: 0.0000 val acc: 0.0000 test loss: 0.1842 test acc: 94.2305 lam_u 1.1963 unlab loss: 0.1685 unlab acc: 94.7934LR: 0.002000
epoch: 50 train loss: 0.0673 train acc: 97.6441 val loss: 0.0000 val acc: 0.0000 test loss: 0.1825 test acc: 94.2261 lam_u 1.2207 unlab loss: 0.1694 unlab acc: 94.7541LR: 0.002000
